{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0242f-9f2a-4f0f-9604-705aaaeff4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install zeno_etl_libs_v3==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47238ac2-f8ab-4370-8a46-f145a0d7d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"main wrapper for IPC2.0 safety stock reset\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil.tz import gettz\n",
    "from ast import literal_eval\n",
    "\n",
    "sys.path.append('../../../..')\n",
    "# sys.path.insert(0,'/Users/tusharuike/ETL')\n",
    "\n",
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.db.db import DB, PostGre\n",
    "from zeno_etl_libs.django.api import Django\n",
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.helper.email.email import Email\n",
    "from zeno_etl_libs.helper import helper\n",
    "\n",
    "from zeno_etl_libs.utils.ipc2.forecast_main import ipc_forecast\n",
    "from zeno_etl_libs.utils.ipc2.safety_stock import safety_stock_calc\n",
    "from zeno_etl_libs.utils.ipc2.portfolio_consolidation import wh_consolidation, \\\n",
    "    goodaid_consolidation, D_class_consolidation\n",
    "from zeno_etl_libs.utils.ipc.store_portfolio_additions import generic_portfolio\n",
    "from zeno_etl_libs.utils.ipc.npi_exclusion import omit_npi_drugs\n",
    "from zeno_etl_libs.utils.ipc2.post_processing import post_processing\n",
    "from zeno_etl_libs.utils.ipc2.helpers.correction_flag import compare_df, \\\n",
    "    add_correction_flag\n",
    "from zeno_etl_libs.utils.ipc.doid_update_ss import doid_update\n",
    "from zeno_etl_libs.utils.ipc2.helpers.outlier_check import check_oup_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a084a-9dd2-4511-953a-12d781ff8343",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd27bb1-e602-4a5b-afd9-fb4535e7c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(debug_mode, reset_stores, reset_date, type_list, reset_store_ops,\n",
    "         v3_active_flag, v4_active_flag, v5_active_flag, v6_active_flag,\n",
    "         d_class_consolidation, wh_gen_consolidation, goodaid_ss_flag,\n",
    "         keep_all_generic_comp, omit_npi, ga_inv_weight, rest_inv_weight,\n",
    "         top_inv_weight, v6_type_list, v6_ptr_cut_off, open_po_turbhe_active,\n",
    "         corrections_selling_probability_cutoff,\n",
    "         corrections_cumulative_probability_cutoff, drug_type_list_v4,\n",
    "         outlier_check, rs_db_read, rs_db_write, read_schema, write_schema,\n",
    "         s3, django, logger):\n",
    "\n",
    "    logger.info(f\"Debug Mode: {debug_mode}\")\n",
    "    status = 'Failed'\n",
    "\n",
    "    # Define empty variables if required in case of fail\n",
    "    order_value_all = pd.DataFrame()\n",
    "    new_drug_entries = pd.DataFrame()\n",
    "    missed_entries = pd.DataFrame()\n",
    "    df_outliers_all = pd.DataFrame()\n",
    "    manual_doid_upd_all = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        for store_id in reset_stores:\n",
    "            logger.info(f\"Running for store id: {store_id} and reset date: {reset_date}\")\n",
    "\n",
    "            if not type_list:\n",
    "                type_list = str(\n",
    "                    list(reset_store_ops.loc[reset_store_ops['store_id'] ==\n",
    "                                             store_id, 'type'].unique()))\n",
    "                type_list = type_list.replace('[', '(').replace(']', ')')\n",
    "\n",
    "            # RUNNING IPC2.0 FORECAST PIPELINE\n",
    "            logger.info(\"Forecast Pipeline starts...\")\n",
    "            agg_fcst, cal_sales, weekly_fcst, seg_df, drug_class = ipc_forecast(\n",
    "                store_id, reset_date, type_list, read_schema, rs_db_read,\n",
    "                logger)\n",
    "\n",
    "            # SAFETY STOCK CALCULATIONS\n",
    "            logger.info(\"Safety Stock Calculations starts...\")\n",
    "            safety_stock_df = safety_stock_calc(\n",
    "                agg_fcst, cal_sales, store_id, reset_date, v3_active_flag,\n",
    "                corrections_selling_probability_cutoff,\n",
    "                corrections_cumulative_probability_cutoff,\n",
    "                v4_active_flag, drug_type_list_v4, v5_active_flag,\n",
    "                open_po_turbhe_active, read_schema, rs_db_read, logger)\n",
    "\n",
    "            # WAREHOUSE GENERIC SKU CONSOLIDATION\n",
    "            if wh_gen_consolidation == 'Y':\n",
    "                logger.info(\"WH Generic Consolidation starts\")\n",
    "                df_pre_corr = safety_stock_df.copy()\n",
    "                safety_stock_df = wh_consolidation(\n",
    "                    safety_stock_df, rs_db_read, read_schema, logger)\n",
    "                df_post_corr = safety_stock_df.copy()\n",
    "                logger.info(f\"Sum OUP before: {df_pre_corr['order_upto_point'].sum()}\")\n",
    "                logger.info(f\"Sum OUP after: {df_post_corr['order_upto_point'].sum()}\")\n",
    "\n",
    "                corr_drug_lst = compare_df(df_pre_corr, df_post_corr, logger)\n",
    "                safety_stock_df = add_correction_flag(safety_stock_df, corr_drug_lst, 'WH')\n",
    "\n",
    "            # GOODAID SAFETY STOCK MODIFICATION\n",
    "            if goodaid_ss_flag == 'Y':\n",
    "                logger.info(\"GA SS Modification starts\")\n",
    "                df_pre_corr = safety_stock_df.copy()\n",
    "                safety_stock_df = goodaid_consolidation(\n",
    "                    safety_stock_df, rs_db_read, read_schema, logger)\n",
    "                df_post_corr = safety_stock_df.copy()\n",
    "                logger.info(f\"Sum OUP before: {df_pre_corr['order_upto_point'].sum()}\")\n",
    "                logger.info(f\"Sum OUP after: {df_post_corr['order_upto_point'].sum()}\")\n",
    "\n",
    "                corr_drug_lst = compare_df(df_pre_corr, df_post_corr, logger)\n",
    "                safety_stock_df = add_correction_flag(safety_stock_df, corr_drug_lst, 'GA')\n",
    "\n",
    "            # D-CLASS SKU CONSOLIDATION\n",
    "            if d_class_consolidation == 'Y':\n",
    "                logger.info(\"D Class Consolidation starts\")\n",
    "                df_pre_corr = safety_stock_df.copy()\n",
    "                safety_stock_df = D_class_consolidation(\n",
    "                    safety_stock_df, store_id, rs_db_read, read_schema, logger)\n",
    "                df_post_corr = safety_stock_df.copy()\n",
    "                logger.info(f\"Sum OUP before: {df_pre_corr['order_upto_point'].sum()}\")\n",
    "                logger.info(f\"Sum OUP after: {df_post_corr['order_upto_point'].sum()}\")\n",
    "\n",
    "                corr_drug_lst = compare_df(df_pre_corr, df_post_corr, logger)\n",
    "                safety_stock_df = add_correction_flag(safety_stock_df, corr_drug_lst, 'DCC')\n",
    "\n",
    "            # KEEP ALL GENERIC COMPOSITIONS IN STORE\n",
    "            if keep_all_generic_comp == 'Y':\n",
    "                logger.info(\"All Generic Composition starts\")\n",
    "                df_pre_corr = safety_stock_df.copy()\n",
    "                safety_stock_df = generic_portfolio(safety_stock_df, rs_db_read,\n",
    "                                                    read_schema, logger)\n",
    "                df_post_corr = safety_stock_df.copy()\n",
    "                logger.info(f\"Sum OUP before: {df_pre_corr['order_upto_point'].sum()}\")\n",
    "                logger.info(f\"Sum OUP after: {df_post_corr['order_upto_point'].sum()}\")\n",
    "\n",
    "                corr_drug_lst = compare_df(df_pre_corr, df_post_corr, logger)\n",
    "                safety_stock_df = add_correction_flag(safety_stock_df, corr_drug_lst, 'AG')\n",
    "\n",
    "            # OMIT NPI DRUGS\n",
    "            if omit_npi == 'Y':\n",
    "                logger.info(\"Omit NPI starts\")\n",
    "                df_pre_corr = safety_stock_df.copy()\n",
    "                safety_stock_df = omit_npi_drugs(safety_stock_df, store_id,\n",
    "                                                 reset_date, rs_db_read,\n",
    "                                                 read_schema, logger)\n",
    "                df_post_corr = safety_stock_df.copy()\n",
    "                logger.info(f\"Sum OUP before: {df_pre_corr['order_upto_point'].sum()}\")\n",
    "                logger.info(f\"Sum OUP after: {df_post_corr['order_upto_point'].sum()}\")\n",
    "\n",
    "                corr_drug_lst = compare_df(df_pre_corr, df_post_corr, logger)\n",
    "                safety_stock_df = add_correction_flag(safety_stock_df, corr_drug_lst, 'NPI')\n",
    "\n",
    "            # POST PROCESSING AND ORDER VALUE CALCULATIONS\n",
    "            logger.info(\"Post Processing starts\")\n",
    "            safety_stock_df, order_value, weekly_fcst, \\\n",
    "                seg_df = post_processing(safety_stock_df, weekly_fcst, seg_df,\n",
    "                                         store_id, read_schema, rs_db_read,\n",
    "                                         logger)\n",
    "            order_value_all = order_value_all.append(order_value, ignore_index=True)\n",
    "\n",
    "            # WRITING TO RS-DB\n",
    "            if debug_mode == 'N':\n",
    "                logger.info(\"Writing table to RS-DB\")\n",
    "                # writing table ipc2-weekly-forecast\n",
    "                # weekly_fcst['store_id'] = weekly_fcst['store_id'].astype(int)\n",
    "                # weekly_fcst['drug_id'] = weekly_fcst['drug_id'].astype(int)\n",
    "                # weekly_fcst['reset_date'] = dt.datetime.strptime(reset_date, '%Y-%m-%d').date()\n",
    "                # weekly_fcst['created-at'] = dt.datetime.now(\n",
    "                #     tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                # weekly_fcst['created-by'] = 'etl-automation'\n",
    "                # weekly_fcst['updated-at'] = dt.datetime.now(\n",
    "                #     tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                # weekly_fcst['updated-by'] = 'etl-automation'\n",
    "                # weekly_fcst.columns = [c.replace('_', '-') for c in\n",
    "                #                        weekly_fcst.columns]\n",
    "                # table_info = helper.get_table_info(db=rs_db_write,\n",
    "                #                                    table_name='ipc2-weekly-forecast',\n",
    "                #                                    schema=write_schema)\n",
    "                # columns = list(table_info['column_name'])\n",
    "                # weekly_fcst = weekly_fcst[columns]  # required column order\n",
    "\n",
    "                # logger.info(\"Writing to table: ipc2-weekly-forecast\")\n",
    "                # s3.write_df_to_db(df=weekly_fcst,\n",
    "                #                   table_name='ipc2-weekly-forecast',\n",
    "                #                   db=rs_db_write, schema=write_schema)\n",
    "\n",
    "                # writing table ipc2-safety-stock\n",
    "                safety_stock_df['store_id'] = safety_stock_df['store_id'].astype(int)\n",
    "                safety_stock_df['drug_id'] = safety_stock_df['drug_id'].astype(int)\n",
    "                safety_stock_df['reset_date'] = dt.datetime.strptime(reset_date, '%Y-%m-%d').date()\n",
    "                safety_stock_df['created-at'] = dt.datetime.now(\n",
    "                    tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                safety_stock_df['created-by'] = 'etl-automation'\n",
    "                safety_stock_df['updated-at'] = dt.datetime.now(\n",
    "                    tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                safety_stock_df['updated-by'] = 'etl-automation'\n",
    "                safety_stock_df.columns = [c.replace('_', '-') for c in\n",
    "                                           safety_stock_df.columns]\n",
    "                table_info = helper.get_table_info(db=rs_db_write,\n",
    "                                                   table_name='ipc2-safety-stock',\n",
    "                                                   schema=write_schema)\n",
    "                columns = list(table_info['column_name'])\n",
    "                safety_stock_df = safety_stock_df[columns]  # required column order\n",
    "\n",
    "                logger.info(\"Writing to table: ipc2-safety-stock\")\n",
    "                s3.write_df_to_db(df=safety_stock_df,\n",
    "                                  table_name='ipc2-safety-stock',\n",
    "                                  db=rs_db_write, schema=write_schema)\n",
    "\n",
    "                # writing table ipc2-segmentation\n",
    "                # seg_df['store_id'] = seg_df['store_id'].astype(int)\n",
    "                # seg_df['drug_id'] = seg_df['drug_id'].astype(int)\n",
    "                # seg_df['reset_date'] = dt.datetime.strptime(reset_date, '%Y-%m-%d').date()\n",
    "                # seg_df['created-at'] = dt.datetime.now(\n",
    "                #     tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                # seg_df['created-by'] = 'etl-automation'\n",
    "                # seg_df['updated-at'] = dt.datetime.now(\n",
    "                #     tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                # seg_df['updated-by'] = 'etl-automation'\n",
    "                # seg_df.columns = [c.replace('_', '-') for c in seg_df.columns]\n",
    "                # table_info = helper.get_table_info(db=rs_db_write,\n",
    "                #                                    table_name='ipc2-segmentation',\n",
    "                #                                    schema=write_schema)\n",
    "                # columns = list(table_info['column_name'])\n",
    "                # seg_df = seg_df[columns]  # required column order\n",
    "\n",
    "                # logger.info(\"Writing to table: ipc2-segmentation\")\n",
    "                # s3.write_df_to_db(df=seg_df,\n",
    "                #                   table_name='ipc2-segmentation',\n",
    "                #                   db=rs_db_write, schema=write_schema)\n",
    "                logger.info(\"All writes to RS-DB completed!\")\n",
    "\n",
    "                # OUP OUTLIER CHECK\n",
    "                if outlier_check == 'Y':\n",
    "                    logger.info(\"Outlier detection starts\")\n",
    "                    outlier_drugs, df_outliers, \\\n",
    "                    manual_doid_upd_df = check_oup_outlier(\n",
    "                        safety_stock_df, store_id, reset_date, rs_db_read,\n",
    "                        read_schema)\n",
    "                    df_outliers_all = df_outliers_all.append(df_outliers)\n",
    "                    manual_doid_upd_all = manual_doid_upd_all.append(manual_doid_upd_df)\n",
    "                else:\n",
    "                    outlier_drugs = []\n",
    "\n",
    "                # UPLOADING MIN, SS, MAX in DOI-D\n",
    "                # logger.info(\"Updating new SS to DrugOrderInfo-Data\")\n",
    "                # safety_stock_df.columns = [c.replace('-', '_') for c in safety_stock_df.columns]\n",
    "                # ss_data_upload = safety_stock_df.loc[\n",
    "                #     (safety_stock_df[\"order_upto_point\"] > 0) &\n",
    "                #     (~safety_stock_df[\"drug_id\"].isin(outlier_drugs))]\n",
    "                # ss_data_upload = ss_data_upload[['store_id', 'drug_id',\n",
    "                #         'safety_stock', 'reorder_point', 'order_upto_point']]\n",
    "                # ss_data_upload.columns = ['store_id', 'drug_id', 'corr_min',\n",
    "                #                           'corr_ss', 'corr_max']\n",
    "                # new_drug_entries_str, missed_entries_str = doid_update(\n",
    "                #     ss_data_upload, type_list, rs_db_write, write_schema,\n",
    "                #     logger)\n",
    "                # new_drug_entries = new_drug_entries.append(new_drug_entries_str)\n",
    "                # missed_entries = missed_entries.append(missed_entries_str)\n",
    "\n",
    "                # INTERNAL TABLE SCHEDULE UPDATE - OPS ORACLE\n",
    "                logger.info(f\"Rescheduling SID:{store_id} in OPS ORACLE\")\n",
    "                if isinstance(reset_store_ops, pd.DataFrame):\n",
    "                    content_type = 74\n",
    "                    object_id = reset_store_ops.loc[\n",
    "                        reset_store_ops[\n",
    "                            'store_id'] == store_id, 'object_id'].unique()\n",
    "                    for obj in object_id:\n",
    "                        request_body = {\"object_id\": int(obj),\n",
    "                                        \"content_type\": content_type}\n",
    "                        api_response, _ = django.django_model_execution_log_create_api(\n",
    "                            request_body)\n",
    "                        reset_store_ops.loc[\n",
    "                            reset_store_ops['object_id'] == obj,\n",
    "                            'api_call_response'] = api_response\n",
    "\n",
    "            else:\n",
    "                logger.info(\"Writing to RS-DB skipped\")\n",
    "\n",
    "        status = 'Success'\n",
    "        logger.info(f\"IPC code execution status: {status}\")\n",
    "\n",
    "    except Exception as error:\n",
    "        logger.exception(error)\n",
    "        logger.info(f\"IPC code execution status: {status}\")\n",
    "\n",
    "    return status, order_value_all, new_drug_entries, missed_entries,\\\n",
    "           df_outliers_all, manual_doid_upd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac2cad-eb65-412b-af72-bdd5626404b3",
   "metadata": {},
   "source": [
    "# Pass Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59344e97-68ab-4dc4-bbbf-c5a034b9c2f1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "env = \"dev\"\n",
    "email_to = \"vivek.revi@zeno.health\"\n",
    "debug_mode = \"N\"\n",
    "run_batch = \"run_batch\"\n",
    "tot_batch = \"tot_batch\"\n",
    "batch_stores = \"batch_stores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2852577-39ff-4934-933c-0e390c950cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['env'] = env\n",
    "\n",
    "logger = get_logger()\n",
    "s3 = S3()\n",
    "django = Django()\n",
    "rs_db_read = DB(read_only=True)\n",
    "rs_db_write = DB(read_only=False)\n",
    "read_schema = 'prod2-generico'\n",
    "write_schema = 'prod2-generico'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dcda5-b48e-4bc1-9650-ee5b1b6877e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open RS connection\n",
    "rs_db_read.open_connection()\n",
    "rs_db_write.open_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637a6df-a1b0-4ba2-b0ec-a626912b810c",
   "metadata": {},
   "source": [
    "# Read params from RS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7966c-67ce-4602-a4d5-2f8169db874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeno_etl_libs.helper.parameter.job_parameter import parameter\n",
    "\n",
    "args = parameter.get_params(job_id=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d119f3-d0b8-4846-b424-5d7f0e294de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOB EXCLUSIVE PARAMS\n",
    "exclude_stores = args[\"exclude_stores\"]\n",
    "goodaid_ss_flag = args[\"goodaid_ss_flag\"]\n",
    "ga_inv_weight = args[\"ga_inv_weight\"]\n",
    "rest_inv_weight = args[\"rest_inv_weight\"]\n",
    "top_inv_weight = args[\"top_inv_weight\"]\n",
    "d_class_consolidation = args[\"d_class_consolidation\"]\n",
    "wh_gen_consolidation = args[\"wh_gen_consolidation\"]\n",
    "v5_active_flag = args[\"v5_active_flag\"]\n",
    "v6_active_flag = args[\"v6_active_flag\"]\n",
    "v6_type_list = args[\"v6_type_list\"]\n",
    "v6_ptr_cut_off = args[\"v6_ptr_cut_off\"]\n",
    "reset_date = args[\"reset_date\"]\n",
    "reset_stores = args[\"reset_stores\"]\n",
    "v3_active_flag = args[\"v3_active_flag\"]\n",
    "v4_active_flag = args[\"v4_active_flag\"]\n",
    "corrections_selling_probability_cutoff = args[\"corrections_selling_probability_cutoff\"]\n",
    "corrections_cumulative_probability_cutoff = args[\"corrections_cumulative_probability_cutoff\"]\n",
    "drug_type_list_v4 = args[\"drug_type_list_v4\"]\n",
    "omit_npi = args[\"omit_npi\"]\n",
    "keep_all_generic_comp = args[\"keep_all_generic_comp\"]\n",
    "outlier_check = args[\"outlier_check\"]\n",
    "open_po_turbhe_active = args[\"open_po_turbhe_active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb956db6-0b90-495e-95d1-b872d282809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_date == 'YYYY-MM-DD':  # Take current date\n",
    "    reset_date = dt.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "if reset_stores == [0]:  # Fetch scheduled IPC stores from OPS ORACLE\n",
    "    store_query = \"\"\"\n",
    "        select \"id\", name, \"opened-at\" as opened_at\n",
    "        from \"{read_schema}\".stores\n",
    "        where name <> 'Zippin Central'\n",
    "        and \"is-active\" = 1\n",
    "        and \"opened-at\" != '0101-01-01 00:00:00'\n",
    "        and id not in {0}\n",
    "        \"\"\".format(str(exclude_stores).replace('[', '(').replace(']', ')'),\n",
    "                   read_schema=read_schema)\n",
    "    stores = rs_db_read.get_df(store_query)\n",
    "    # only stores aged > 3 months are eligible\n",
    "    store_id = stores.loc[dt.datetime.now() -\n",
    "                          stores['opened_at'] >\n",
    "                          dt.timedelta(days=90), 'id'].values\n",
    "\n",
    "    # QUERY TO GET SCHEDULED STORES AND TYPE FROM OPS ORACLE\n",
    "    pg_internal = PostGre(is_internal=True)\n",
    "    pg_internal.open_connection()\n",
    "    reset_store_query = \"\"\"\n",
    "        SELECT\n",
    "            \"ssr\".\"id\" as object_id,\n",
    "            \"s\".\"bpos_store_id\" as store_id,\n",
    "            \"dc\".\"slug\" as type,\n",
    "            \"ssr\".\"drug_grade\"\n",
    "        FROM\n",
    "            \"safety_stock_reset_drug_category_mapping\" ssr\n",
    "            INNER JOIN \"ops_store_manifest\" osm\n",
    "            ON ( \"ssr\".\"ops_store_manifest_id\" = \"osm\".\"id\" )\n",
    "            INNER JOIN \"retail_store\" s\n",
    "            ON ( \"osm\".\"store_id\" = \"s\".\"id\" )\n",
    "            INNER JOIN \"drug_category\" dc\n",
    "            ON ( \"ssr\".\"drug_category_id\" = \"dc\".\"id\")\n",
    "        WHERE\n",
    "            (\n",
    "                ( \"ssr\".\"should_run_daily\" = TRUE OR\n",
    "                    \"ssr\".\"trigger_dates\" && ARRAY[ date('{reset_date}')] )\n",
    "                AND \"ssr\".\"is_auto_generate\" = TRUE\n",
    "                AND \"osm\".\"is_active\" = TRUE\n",
    "            AND \"osm\".\"is_generate_safety_stock_reset\" = TRUE\n",
    "            AND \"dc\".\"is_safety_stock_reset_enabled\" = TRUE\n",
    "            AND \"dc\".\"is_active\" = TRUE\n",
    "            AND s.bpos_store_id in {store_list}\n",
    "            )\n",
    "        \"\"\".format(\n",
    "        store_list=str(list(store_id)).replace('[', '(').replace(']', ')'),\n",
    "        reset_date=reset_date)\n",
    "    reset_store_ops = pd.read_sql_query(reset_store_query,\n",
    "                                        pg_internal.connection)\n",
    "    pg_internal.close_connection()\n",
    "\n",
    "    reset_store_ops['api_call_response'] = False\n",
    "    scheduled_stores = reset_store_ops['store_id'].unique()\n",
    "    type_list = None\n",
    "    \n",
    "    # for batch run\n",
    "    reset_stores = list(set(scheduled_stores).intersection(batch_stores))\n",
    "\n",
    "else:\n",
    "    type_list = \"('ethical', 'ayurvedic', 'generic', 'discontinued-products', \" \\\n",
    "                \"'banned', 'general', 'high-value-ethical', 'baby-product',\" \\\n",
    "                \" 'surgical', 'otc', 'glucose-test-kit', 'category-2', \" \\\n",
    "                \"'category-1', 'category-4', 'baby-food', '', 'category-3')\"\n",
    "    reset_store_ops = None\n",
    "    \n",
    "    # for batch run\n",
    "    reset_stores = list(set(reset_stores).intersection(batch_stores))\n",
    "    scheduled_stores = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab407339-83f3-474a-8ebe-10b0b8b4a69f",
   "metadata": {},
   "source": [
    "# Execute Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3480b8b-abb6-4e7a-b405-b73dfb53fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" calling the main function \"\"\"\n",
    "status, order_value_all, new_drug_entries, missed_entries, \\\n",
    "df_outliers_all, manual_doid_upd_all = main(\n",
    "    debug_mode, reset_stores, reset_date, type_list, reset_store_ops,\n",
    "    v3_active_flag, v4_active_flag, v5_active_flag, v6_active_flag,\n",
    "    d_class_consolidation, wh_gen_consolidation, goodaid_ss_flag,\n",
    "    keep_all_generic_comp, omit_npi, ga_inv_weight, rest_inv_weight,\n",
    "    top_inv_weight, v6_type_list, v6_ptr_cut_off, open_po_turbhe_active,\n",
    "    corrections_selling_probability_cutoff,\n",
    "    corrections_cumulative_probability_cutoff, drug_type_list_v4,\n",
    "    outlier_check, rs_db_read, rs_db_write, read_schema, write_schema,\n",
    "    s3, django, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ca96b-3d9e-4302-8338-6d1e7e130391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close RS connection\n",
    "rs_db_read.close_connection()\n",
    "rs_db_write.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98179c3-7b94-4586-80c9-98389d26541e",
   "metadata": {},
   "source": [
    "# Send Email Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdb945-98cb-48c2-92b9-99a6e92333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save email attachements to s3\n",
    "order_value_all_uri = s3.save_df_to_s3(order_value_all,\n",
    "                                       file_name=f\"order_value_all_{reset_date}.csv\")\n",
    "new_drug_entries_uri = s3.save_df_to_s3(new_drug_entries,\n",
    "                                        file_name=f\"new_drug_entries_{reset_date}.csv\")\n",
    "missed_entries_uri = s3.save_df_to_s3(missed_entries,\n",
    "                                      file_name=f\"missed_entries_{reset_date}.csv\")\n",
    "df_outliers_all_uri = s3.save_df_to_s3(df_outliers_all,\n",
    "                                      file_name=f\"df_outliers_all_{reset_date}.csv\")\n",
    "manual_doid_upd_all_uri = s3.save_df_to_s3(manual_doid_upd_all,\n",
    "                                      file_name=f\"manual_doid_upd_all_{reset_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9bf00a-ec0b-4693-a9ca-495bdf932054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEND EMAIL ATTACHMENTS (IPC-RUN STATUS)\n",
    "logger.info(\"Sending email attachments..\")\n",
    "email = Email()\n",
    "email.send_email_file(\n",
    "    subject=f\"IPC2.0 SS Reset: (SM-{env}) {reset_date}: {status}\",\n",
    "    mail_body=f\"\"\"\n",
    "            Debug Mode: {debug_mode}\n",
    "            Batch: {str(run_batch)+'/'+str(tot_batch)}\n",
    "            Batch Stores: {batch_stores}\n",
    "            Reset Stores: {reset_stores}\n",
    "            Scheduled Stores: {scheduled_stores}\n",
    "            Job Params: {args}\n",
    "            \"\"\",\n",
    "    to_emails=email_to, file_uris=[order_value_all_uri,\n",
    "                                   new_drug_entries_uri,\n",
    "                                   missed_entries_uri])\n",
    "\n",
    "# SEND EMAIL ATTACHMENTS (OUTLIER WARNING)\n",
    "outlier_count = df_outliers_all.shape[0]\n",
    "if outlier_count > 0:\n",
    "    outlier_order_qty = df_outliers_all[\"to_order_quantity\"].sum()\n",
    "    outlier_order_val = round(df_outliers_all[\"to_order_value\"].sum(), 2)\n",
    "    outlier_stores = list(df_outliers_all[\"store_id\"].unique())\n",
    "    email.send_email_file(\n",
    "        subject=f\"IPC2.0 OUTLIER WARNING (SM-{env}) {reset_date}: \"\n",
    "                f\"Cases {outlier_count}\",\n",
    "        mail_body=f\"\"\"\n",
    "                Batch: {str(run_batch)+'/'+str(tot_batch)}\n",
    "                Stores: {outlier_stores}\n",
    "                Cases: {outlier_count}\n",
    "                Order Quantity: {outlier_order_qty}\n",
    "                Order Value: {outlier_order_val}\n",
    "                Note: For the detected cases SS, ROP & OUP is set to 0. \n",
    "                Please verify and upload attached file using DOID-GLUE JOB.\n",
    "                \"\"\",\n",
    "        to_emails=email_to, file_uris=[df_outliers_all_uri,\n",
    "                                       manual_doid_upd_all_uri])\n",
    "\n",
    "logger.info(\"Script ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c6ebf-63d8-409e-813d-3897ed115fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
