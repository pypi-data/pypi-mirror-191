{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94553be3-8bef-427f-9de7-c71bf4ac0040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zeno-etl-libs==1.0.40 in c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages (1.0.40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl==3.0.9 in c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages (from openpyxl==3.0.9) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#installing extra libraries on prod\n",
    "!pip install zeno-etl-libs-v3==1.0.1\n",
    "!pip install openpyxl==3.0.9\n",
    "!pip install nltk==3.6.7\n",
    "!pip install tweepy==4.3.0\n",
    "!pip install apiclient==1.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6aa4c66-16c9-4c2a-965f-67bf3705eabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFetching Playstore reviews on daily basis\\nAuthor : neha.karekar@zeno.health\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fetching Playstore reviews on daily basis\n",
    "Author : neha.karekar@zeno.health\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf98df5-b7c7-4eef-897d-ef6ba03a0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "import datetime\n",
    "from dateutil.tz import gettz\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed0844b-8b07-4227-a737-b4c43ca38abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')  # divides a whole text data into sentences\n",
    "nltk.download('vader_lexicon')\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fbe3aa-ed6b-499a-9092-f57d2fe64528",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe37241-fcfb-4454-8fe9-f0c34382111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.db.db import DB\n",
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.helper import helper\n",
    "from zeno_etl_libs.helper.email.email import Email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23ce67-10fe-4c6c-905a-c31b90a986d9",
   "metadata": {},
   "source": [
    "## Pass Params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9634ce4b-146a-46da-9617-ca0ba512651a",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "env = \"dev\"\n",
    "full_run = 0\n",
    "email_to =\"neha.karekar@zeno.health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08851736-d86a-4a24-995d-49edc2523726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-24 13:01:31,071 - root - INFO - full_run: 0\n"
     ]
    }
   ],
   "source": [
    "os.environ['env'] = env\n",
    "logger = get_logger()\n",
    "logger.info(f\"full_run: {full_run}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3174702-f55f-4bec-8c59-47c02ab52d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_db = DB(read_only=False)\n",
    "rs_db.open_connection()\n",
    "s3 = S3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd920692-714f-4450-8290-d337fc03a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'prod2-generico'\n",
    "table_name = 'zeno-tweets'\n",
    "table_info = helper.get_table_info(db=rs_db, table_name=table_name, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979f8d9a-ffce-461b-9e0e-da756552cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   max_exp  1 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 136.0 bytes\n",
      "None\n",
      "2022-06-22 19:50:03\n"
     ]
    }
   ],
   "source": [
    "# max of data\n",
    "table_q = \"\"\"\n",
    "select\n",
    "            max(\"tweet-created-at\") max_exp\n",
    "        from\n",
    "            \"prod2-generico\".\"zeno-tweets\" \n",
    "        \"\"\"\n",
    "max_exp_date = rs_db.get_df(table_q)\n",
    "max_exp_date['max_exp'].fillna(np.nan, inplace=True)\n",
    "print(max_exp_date.info())\n",
    "max_exp_date = max_exp_date['max_exp'].to_string(index=False)\n",
    "print(max_exp_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f587d8a-0125-474c-bae5-9c1298fa9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "if full_run or max_exp_date == 'NaN':\n",
    "    start = '2017-05-13'\n",
    "else:\n",
    "    start = max_exp_date\n",
    "start = dateutil.parser.parse(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd3f71d-60a2-4dad-beba-bfca31bd5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining keys and tokens\n",
    "\n",
    "consumer_key = 'c57SU7sulViKSmjsOTi4kTO3W'\n",
    "consumer_secret = 'cNT3yk5ibQ315AWNCJHgE9ipCGlM1XnenHZu9cBWaVL3q7fPew'\n",
    "access_token = '796747210159517701-DhOBQgwzeb6q4eXlI4WjwPRJH1CuEIT'\n",
    "access_token_secret = 'sMrnPZ4ExI8um43wquUvFEUCTyY61HYRf7z3jv00ltXlt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4d6e42-6256-4bab-a0f8-175f9d328608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making api connection\n",
    "\n",
    "# authentication\n",
    "\n",
    "def auth(consumer_key, consumer_secret, access_token, access_token_secret):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebff49a1-80a1-4047-b016-56b4c2add25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = auth(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35c1b93-a666-416d-a3c7-64babc61a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove url\n",
    "def remove_url(txt):\n",
    "    \"\"\"Replace URLs found in a text string with nothing\n",
    "    (i.e. it will remove the URL from the string).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to parse and remove urls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The same txt string with url's removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8cb2e3f-f04b-46ad-8020-fde95763563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for the keyword in tweeter and tokenizing it\n",
    "def tweet(search_term, count=100000):\n",
    "    # Create a custom search term and define the number of tweets\n",
    "    tweets = api.search_tweets(search_term, count=count)\n",
    "\n",
    "    # Remove URLs\n",
    "    tweets_no_urls = [remove_url(tweet.text) for tweet in tweets]\n",
    "    # lowercase\n",
    "    tweet_data = [sent_tokenize(x.lower()) for x in tweets_no_urls]\n",
    "    tweet_data = pd.DataFrame(data=tweet_data, columns=['tweetext'])\n",
    "    tweet_att = [[search_term, x.lang, x.user.location, x.created_at, x.id, x.user.name,\n",
    "                  x.user.followers_count, x.user.friends_count, x.text, x.place, x.user.time_zone] for x in tweets]\n",
    "    tweet_att = pd.DataFrame(data=tweet_att, columns=['search_term', 'lang', 'loc', 'created-at', 'id', 'username',\n",
    "                                                      'followers', 'friends', 'og tweet', 'place', 'Tz'])\n",
    "    final_data = pd.concat([tweet_data, tweet_att], axis=1)\n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c7fa334-063f-4bf8-b193-6dd247cdd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def remove_sw(sent, corpus):\n",
    "    stop_words = set(stopwords.words(corpus))\n",
    "\n",
    "    word_tokens = word_tokenize(sent)\n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "    filtered_sentence = []\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    filtered_sentence = ' '.join(filtered_sentence)\n",
    "    return [filtered_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f95816-b3fb-42dd-ada8-204ee3ea287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding sentiment intensity analyzer\n",
    "def sentiment_analyser(lst):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment = [sid.polarity_scores(x) for x in lst]\n",
    "    neg = [sid.polarity_scores(x)['neg'] for x in lst]\n",
    "    neu = [sid.polarity_scores(x)['neu'] for x in lst]\n",
    "    pos = [sid.polarity_scores(x)['pos'] for x in lst]\n",
    "    comp = [sid.polarity_scores(x)['compound'] for x in lst]\n",
    "\n",
    "    return neg[0], neu[0], pos[0], comp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e67917a-9a26-46e2-a0b9-1a45c3b28ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running all above functions\n",
    "def run_all(search_term, count=1000000):\n",
    "    print(\"API handshake successful\")\n",
    "    print(\"Searching for term \", search_term)\n",
    "    tweet_data = tweet(search_term, count=count)\n",
    "    # print(tweet_data)\n",
    "    print(\"Removing stopwords\")\n",
    "    sw = 'english'\n",
    "    if tweet_data.empty:\n",
    "        return tweet_data\n",
    "    else:\n",
    "        tweet_data['tweetext_filter'] = tweet_data['tweetext'].apply(lambda x: remove_sw(x, sw), 1)\n",
    "        print(\"Analysing sentiment for \", search_term)\n",
    "        tweet_data['neg', 'neu', 'pos', 'comp'] = tweet_data['tweetext_filter'].apply(lambda x: sentiment_analyser(x), 1)\n",
    "        tweet_data[['neg', 'neu', 'pos', 'comp']] = tweet_data['neg', 'neu', 'pos', 'comp'].apply(pd.Series)\n",
    "        tweet_data.drop(columns=('neg', 'neu', 'pos', 'comp'), inplace=True)\n",
    "        # sentiment, neg, neu, pos, comp = sentiment_analyser(tweets)\n",
    "        # df = build_df(pos,neg,neu,comp, tweets)\n",
    "        print('Done \\n')\n",
    "        return tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348a2551-ca37-4c63-b35d-6b1f21fb3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['#zeno_health','@zeno_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f183f6cc-f6a4-4066-97b2-b69584d99cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API handshake successful\n",
      "Searching for term  #zeno_health\n",
      "Removing stopwords\n",
      "Done\n",
      "API handshake successful\n",
      "Searching for term  @zeno_health\n",
      "Removing stopwords\n",
      "Analysing sentiment for  @zeno_health\n",
      "Done \n",
      "\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetext</th>\n",
       "      <th>search_term</th>\n",
       "      <th>lang</th>\n",
       "      <th>loc</th>\n",
       "      <th>created-at</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>og tweet</th>\n",
       "      <th>place</th>\n",
       "      <th>Tz</th>\n",
       "      <th>tweetext_filter</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pharmeasyapp</td>\n",
       "      <td>@zeno_health</td>\n",
       "      <td>hi</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>2022-06-22 14:20:03+00:00</td>\n",
       "      <td>1539614195708477441</td>\n",
       "      <td>Jafar Usman Shaikh</td>\n",
       "      <td>77</td>\n",
       "      <td>503</td>\n",
       "      <td>@pharmeasyapp अभी तक हमारे कंप्लेंट एक्साइलेट ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[pharmeasyapp]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zenohealth a bearded cannot do the job of a ph...</td>\n",
       "      <td>@zeno_health</td>\n",
       "      <td>en</td>\n",
       "      <td>Uttar Pradesh/Jaipur/Mumbai</td>\n",
       "      <td>2022-06-21 07:45:25+00:00</td>\n",
       "      <td>1539152496907923456</td>\n",
       "      <td>DRx. Hamid Raza</td>\n",
       "      <td>7882</td>\n",
       "      <td>4409</td>\n",
       "      <td>- @zeno_health ,\\nA bearded cannot do the job ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[zenohealth bearded job pharmacist companywhy]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>siddharthgadia1 not got my full report magnesi...</td>\n",
       "      <td>@zeno_health</td>\n",
       "      <td>en</td>\n",
       "      <td>bang lore</td>\n",
       "      <td>2022-06-20 15:45:04+00:00</td>\n",
       "      <td>1538910816153616384</td>\n",
       "      <td>Prasun Ashis Sengupta</td>\n",
       "      <td>37</td>\n",
       "      <td>447</td>\n",
       "      <td>@SiddharthGadia1 Not got my full report , magn...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[siddharthgadia1 got full report magnesium rep...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zenohealth magnesium report not got still waiting</td>\n",
       "      <td>@zeno_health</td>\n",
       "      <td>en</td>\n",
       "      <td>bang lore</td>\n",
       "      <td>2022-06-20 15:42:58+00:00</td>\n",
       "      <td>1538910288111714304</td>\n",
       "      <td>Prasun Ashis Sengupta</td>\n",
       "      <td>37</td>\n",
       "      <td>447</td>\n",
       "      <td>@zeno_health Magnesium report not got still wa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[zenohealth magnesium report got still waiting]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweetext   search_term lang  \\\n",
       "0                                       pharmeasyapp  @zeno_health   hi   \n",
       "6  zenohealth a bearded cannot do the job of a ph...  @zeno_health   en   \n",
       "7  siddharthgadia1 not got my full report magnesi...  @zeno_health   en   \n",
       "8  zenohealth magnesium report not got still waiting  @zeno_health   en   \n",
       "\n",
       "                           loc                created-at                   id  \\\n",
       "0                Mumbai, India 2022-06-22 14:20:03+00:00  1539614195708477441   \n",
       "6  Uttar Pradesh/Jaipur/Mumbai 2022-06-21 07:45:25+00:00  1539152496907923456   \n",
       "7                    bang lore 2022-06-20 15:45:04+00:00  1538910816153616384   \n",
       "8                    bang lore 2022-06-20 15:42:58+00:00  1538910288111714304   \n",
       "\n",
       "                username followers friends  \\\n",
       "0     Jafar Usman Shaikh        77     503   \n",
       "6        DRx. Hamid Raza      7882    4409   \n",
       "7  Prasun Ashis Sengupta        37     447   \n",
       "8  Prasun Ashis Sengupta        37     447   \n",
       "\n",
       "                                            og tweet place    Tz  \\\n",
       "0  @pharmeasyapp अभी तक हमारे कंप्लेंट एक्साइलेट ...  None  None   \n",
       "6  - @zeno_health ,\\nA bearded cannot do the job ...  None  None   \n",
       "7  @SiddharthGadia1 Not got my full report , magn...  None  None   \n",
       "8  @zeno_health Magnesium report not got still wa...  None  None   \n",
       "\n",
       "                                     tweetext_filter  neg  neu  pos  comp  \n",
       "0                                     [pharmeasyapp]  0.0  1.0  0.0   0.0  \n",
       "6     [zenohealth bearded job pharmacist companywhy]  0.0  1.0  0.0   0.0  \n",
       "7  [siddharthgadia1 got full report magnesium rep...  0.0  1.0  0.0   0.0  \n",
       "8    [zenohealth magnesium report got still waiting]  0.0  1.0  0.0   0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tws = pd.DataFrame()\n",
    "try:\n",
    "    for search_term in search_terms:\n",
    "        tw = run_all(search_term, count=1000000)\n",
    "        tws = pd.concat([tws, tw], axis=0)\n",
    "        print('Done')\n",
    "        tws = tws[((tws['lang'].isin(['en', 'hi']) & (~tws['tweetext'].str.startswith('rt'))))]\n",
    "except BaseException as e:\n",
    "    print('failed on_status,', str(e))\n",
    "    time.sleep(3)\n",
    "tws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5158cef4-aec6-42b8-af23-937567611d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tws.empty:\n",
    "    print('DataFrame is empty!')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "128985c5-1133-4ebf-a421-093b527f955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages\\pandas\\core\\frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tws = tws[\n",
    "    ['og tweet', 'id', 'created-at', 'search_term', 'lang', 'loc', 'username', 'followers', 'friends', 'neg', 'neu',\n",
    "     'pos', 'comp']]\n",
    "dict = {'id': 'tweet-id',\n",
    "        'og tweet': 'tweet',\n",
    "        'search_term': 'search-term',\n",
    "        'lang': 'language',\n",
    "        'loc': 'location',\n",
    "        'created-at': 'tweet-created-at',\n",
    "        'pos': 'positive-sentiment',\n",
    "        'neu': 'neutral-sentiment',\n",
    "        'neg': 'negative-sentiment',\n",
    "        'comp': 'compound-sentiment'}\n",
    "tws.rename(columns=dict, inplace=True)\n",
    "tws['tweet-created-at'] = pd.to_datetime(tws['tweet-created-at']). \\\n",
    "    dt.tz_convert('Asia/Kolkata').dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25ce4c93-2d1e-4a7b-b21b-768a4bfc5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\lenovo\\documents\\generico-projects\\etl\\etl_env\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# etl\n",
    "tws['created-at'] = datetime.datetime.now(tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "tws['updated-at'] = datetime.datetime.now(tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "tws['created-by'] = 'etl-automation'\n",
    "tws['updated-by'] = 'etl-automation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec1fbb5b-3e75-46ae-a64c-8924c953277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tws['tweet-type'] = np.where(tws['negative-sentiment'] >= tws['positive-sentiment'], 'Detractor', 'Promoter')\n",
    "tws_mail = tws[['tweet-id', 'tweet', 'tweet-created-at', 'search-term', 'language', 'location', 'username', 'followers',\n",
    "                'friends', 'tweet-type']]\n",
    "tws_mail = tws_mail.sort_values(by=['tweet-type'], ascending=True)\n",
    "tws_mail = tws_mail[(tws_mail['tweet-created-at'] > start)]\n",
    "tws = tws[(tws['tweet-created-at'] > start)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74a47011-c742-4b8d-bfdd-7ac78af412c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is empty!\n",
      "Redshift DB connection closed successfully.\n"
     ]
    }
   ],
   "source": [
    "if tws.empty:\n",
    "    print('DataFrame is empty!')\n",
    "    rs_db.close_connection()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2103bc27-dec6-40d7-ac6a-c7d145362bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tws.columns = [c.replace('_', '-') for c in tws.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd1565fd-018a-42ab-9735-baa1908e60bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-24 12:58:00,342 - root - INFO - Table:zeno-tweets exists\n",
      "2022-06-24 12:58:00,342 - root - INFO - Table:zeno-tweets exists\n"
     ]
    }
   ],
   "source": [
    "if isinstance(table_info, type(None)):\n",
    "    raise Exception(f\"table: {table_name} do not exist, create the table first\")\n",
    "else:\n",
    "    logger.info(f\"Table:{table_name} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec81c024-d694-46d0-935a-3b4a3e33e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DELETE FROM \"prod2-generico\".\"zeno-tweets\" where \"tweet-created-at\" >'2017-05-13 00:00:00' \n"
     ]
    }
   ],
   "source": [
    "truncate_query = f''' DELETE FROM \"{schema}\".\"{table_name}\" where \"tweet-created-at\" >'{start}' '''\n",
    "print(truncate_query)\n",
    "rs_db.execute(truncate_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1b178b9-a617-4cb8-aa26-9a0f9f37c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 object(uri: s3://aws-glue-temporary-921939243643-ap-south-1/temp_1656055685080.csv) delete response: {'ResponseMetadata': {'RequestId': 'BEHB3C7JT6ZZHEQC', 'HostId': 'GjYrgimhUpH/1zTROddWFittBxwftqLpfZtPDfUT/NomkeHJNJ5emKFCh66Cs0W8vMG2L9CkQCE=', 'HTTPStatusCode': 204, 'HTTPHeaders': {'x-amz-id-2': 'GjYrgimhUpH/1zTROddWFittBxwftqLpfZtPDfUT/NomkeHJNJ5emKFCh66Cs0W8vMG2L9CkQCE=', 'x-amz-request-id': 'BEHB3C7JT6ZZHEQC', 'date': 'Fri, 24 Jun 2022 07:28:05 GMT', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n",
      "S3 object(uri: s3://aws-glue-temporary-921939243643-ap-south-1/temp_1656055685080.csv) delete response: {'ResponseMetadata': {'RequestId': 'BEH25PZYHMC7CNN4', 'HostId': 'SYR26P0aRbfF9QX1VDHGJ7lgdRqe1G/rjXqTDfZegVgldYFVqJhYe08Ao448hMwvCOIBcbdNAVo=', 'HTTPStatusCode': 204, 'HTTPHeaders': {'x-amz-id-2': 'SYR26P0aRbfF9QX1VDHGJ7lgdRqe1G/rjXqTDfZegVgldYFVqJhYe08Ao448hMwvCOIBcbdNAVo=', 'x-amz-request-id': 'BEH25PZYHMC7CNN4', 'date': 'Fri, 24 Jun 2022 07:28:05 GMT', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "s3.write_df_to_db(df=tws[table_info['column_name']], table_name=table_name, db=rs_db,\n",
    "                  schema=schema)\n",
    "file_name = 'Zeno_Tweets.xlsx'\n",
    "file_path = s3.write_df_to_excel(data={'Zeno Tweets': tws_mail}, file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1bc1a7c-7b2a-4ae9-837d-a905b9727031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-24 12:58:06,387 - root - INFO - Email sending successful: {\"status\":100,\"message\":\"Successfully called back !\",\"is_error\":false,\"data\":\"Email sending...\"}\n",
      "2022-06-24 12:58:06,387 - root - INFO - Email sending successful: {\"status\":100,\"message\":\"Successfully called back !\",\"is_error\":false,\"data\":\"Email sending...\"}\n",
      "2022-06-24 12:58:06,387 - root - INFO - Email sending successful: {\"status\":100,\"message\":\"Successfully called back !\",\"is_error\":false,\"data\":\"Email sending...\"}\n"
     ]
    }
   ],
   "source": [
    "email = Email()\n",
    "# file_path ='/Users/Lenovo/Downloads/utter.csv'\n",
    "email.send_email_file(subject=\"Zeno Tweets\",\n",
    "                      mail_body='Zeno Tweets',\n",
    "                      to_emails=email_to, file_uris=[], file_paths=[file_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7101a472-5c00-4f2a-9037-b650aa9aef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift DB connection closed successfully.\n"
     ]
    }
   ],
   "source": [
    "rs_db.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3aae28-dd23-4ae9-92ca-a0090428c72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
