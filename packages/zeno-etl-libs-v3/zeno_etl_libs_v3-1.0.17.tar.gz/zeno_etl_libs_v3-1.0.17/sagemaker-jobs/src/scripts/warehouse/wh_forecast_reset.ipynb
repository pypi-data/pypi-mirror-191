{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8a157-b96e-4e0f-bcce-7d438c968ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install zeno_etl_libs_v3==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b3fc5-710a-42d9-ba96-bb98a09425bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Apr 21 21:45:59 2022\n",
    "\n",
    "@author: vivek.sidagam@zeno.health\n",
    "\n",
    "@Purpose: To generate forecast and replenishment figures for Warehouse\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "sys.path.append('../../../..')\n",
    "\n",
    "from zeno_etl_libs.db.db import DB\n",
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.helper.email.email import Email\n",
    "\n",
    "from zeno_etl_libs.utils.warehouse.data_prep.wh_data_prep import wh_data_prep\n",
    "from zeno_etl_libs.utils.warehouse.forecast.forecast_main import wh_forecast\n",
    "from zeno_etl_libs.utils.warehouse.safety_stock.wh_safety_stock import \\\n",
    "    wh_safety_stock_calc\n",
    "from zeno_etl_libs.utils.ipc.doid_update_ss import doid_update\n",
    "from zeno_etl_libs.helper.parameter.job_parameter import parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099121c-070f-4151-8819-9b99195b7493",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#tag = parameters\n",
    "env = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcc56d-b3f1-49bd-bec2-2004cb503fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['env'] = env\n",
    "# runtime variables\n",
    "job_params = parameter.get_params(job_id=117)\n",
    "ss_runtime_var = {'lead_time_mean': job_params['lead_time_mean'],\n",
    "                  'lead_time_std': job_params['lead_time_std'],\n",
    "                  'service_level': job_params['service_level'],\n",
    "                  'ordering_freq': job_params['ordering_freq'],\n",
    "                  'max_review_period': job_params['max_review_period'],\n",
    "                  'z': round(norm.ppf(job_params['service_level']), 2),\n",
    "                  'for_next_month': job_params['for_next_month'],\n",
    "                  'cap_ss_days': job_params['cap_ss_days'],\n",
    "                  'use_fcst_error': job_params['use_fcst_error'],\n",
    "                  'fcst_hist_to_use': job_params['fcst_hist_to_use'],\n",
    "                  'debug_mode': job_params['debug_mode'],\n",
    "                  'simulate_for': job_params['simulate_for']}\n",
    "email_to = job_params['email_to']\n",
    "debug_mode = job_params['debug_mode']\n",
    "simulate_for = job_params['simulate_for']\n",
    "err_msg = ''\n",
    "df_uri = ''\n",
    "schema = job_params['schema']\n",
    "reset = job_params['reset']\n",
    "wh_id = job_params['wh_id']\n",
    "nso_history_days = job_params['nso_history_days']\n",
    "status = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d65ed-4a8d-444d-8007-49c4c4ab67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "logger.info(\"Scripts begins\")\n",
    "logger.info(\"Run time variables --> \" + str(ss_runtime_var))\n",
    "\n",
    "# getting run date for the script\n",
    "if debug_mode == 'Y' and simulate_for != '':\n",
    "    reset_date = simulate_for\n",
    "    current_month_date = (pd.to_datetime(simulate_for).date() - timedelta(days=pd.to_datetime(simulate_for).day - 1))\n",
    "else:\n",
    "    reset_date = str(datetime.now(tz=gettz('Asia/Kolkata')).date())\n",
    "    current_month_date = (datetime.now(tz=gettz('Asia/Kolkata')).date() -\n",
    "                          timedelta(days=datetime.now(tz=gettz('Asia/Kolkata')).day - 1))\n",
    "\n",
    "if ss_runtime_var['for_next_month'] == 'Y':\n",
    "    forecast_date = str(\n",
    "        datetime(current_month_date.year +\n",
    "                 int(current_month_date.month / 12),\n",
    "                 ((current_month_date.month % 12) + 1), 1).date())\n",
    "else:\n",
    "    forecast_date = str(current_month_date)\n",
    "\n",
    "logger.info(f\"\"\"\n",
    "debug_mode --> {debug_mode}\n",
    "reset_date --> {reset_date}, \n",
    "current_month_date --> {current_month_date}, \n",
    "forecast_date --> {forecast_date}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaca412-1551-4464-9377-673e8ac6f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rs_db = DB()\n",
    "    rs_db.open_connection()\n",
    "    logger.info('reading input file to get expected_nso')\n",
    "    params_table_query = \"\"\"\n",
    "            select\n",
    "                \"month-begin-dt\" as month_begin_dt,\n",
    "                value as expected_nso\n",
    "            from\n",
    "                \"prod2-generico\".\"wh-forecast-repln-input\"\n",
    "            where\n",
    "                \"param-name\" = 'expected_nso'\n",
    "        \"\"\"\n",
    "    params_table = rs_db.get_df(params_table_query)\n",
    "    logger.info('expected_nso parameter read')\n",
    "    params_table = params_table.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    params_table['month_begin_dt'] = params_table['month_begin_dt'].astype(str)\n",
    "\n",
    "    try:\n",
    "        expected_nso = int(params_table[\n",
    "                               params_table[\n",
    "                                   'month_begin_dt'] == forecast_date][\n",
    "                               'expected_nso'])\n",
    "    except Exception as error:\n",
    "        expected_nso = 0\n",
    "    logger.info(f\"expected_nso --> {expected_nso}\")\n",
    "\n",
    "    store_query = '''\n",
    "        select\n",
    "            \"id\",\n",
    "            name,\n",
    "            \"opened-at\" as opened_at\n",
    "        from\n",
    "            \"prod2-generico\".stores\n",
    "        where\n",
    "            \"name\" <> 'Zippin Central'\n",
    "            and \"is-active\" = 1\n",
    "            and \"opened-at\" != '0101-01-01 00:00:00'\n",
    "            and id not in (92, 52)\n",
    "    '''\n",
    "    stores = rs_db.get_df(store_query)\n",
    "    store_id_list = list(stores['id'])\n",
    "\n",
    "    new_drug_entries = pd.DataFrame()\n",
    "    missed_entries = pd.DataFrame()\n",
    "\n",
    "    # CONSIDERING DRUG TYPES FOR DATA LOAD\n",
    "    type_list = rs_db.get_df(\n",
    "        'select distinct type from \"prod2-generico\".drugs')\n",
    "    type_list = tuple(type_list[\n",
    "                          ~type_list.type.isin(\n",
    "                              ['', 'banned', 'discontinued-products'])][\n",
    "                          'type'])\n",
    "\n",
    "    # RUNNING DATA PREPARATION\n",
    "    drug_sales_monthly, wh_drug_list, drug_history, demand_daily_deviation = wh_data_prep(\n",
    "        store_id_list, current_month_date, reset_date, type_list, rs_db, logger,\n",
    "        ss_runtime_var, schema)\n",
    "    drug_sales_monthly['drug_id'] = drug_sales_monthly['drug_id'].astype(int, errors='ignore')\n",
    "    drug_sales_monthly['year'] = drug_sales_monthly['year'].astype(int, errors='ignore')\n",
    "    drug_sales_monthly['month'] = drug_sales_monthly['month'].astype(int, errors='ignore')\n",
    "    drug_sales_monthly['net_sales_quantity'] = drug_sales_monthly['net_sales_quantity'].astype(int, errors='ignore')\n",
    "    drug_history = drug_history.astype(int, errors='ignore')\n",
    "    drug_sales_monthly['reset_date'] = reset_date\n",
    "\n",
    "    # FORECASTING\n",
    "    train, train_error, predict, wh_train, wh_train_error, wh_predict = wh_forecast(\n",
    "        drug_sales_monthly, wh_drug_list, drug_history, logger)\n",
    "\n",
    "    train['wh_id'] = wh_id\n",
    "    train_error['wh_id'] = wh_id\n",
    "    predict['wh_id'] = wh_id\n",
    "    wh_train['wh_id'] = wh_id\n",
    "    wh_train_error['wh_id'] = wh_id\n",
    "    wh_predict['wh_id'] = wh_id\n",
    "    train['forecast_date'] = forecast_date\n",
    "    train_error['forecast_date'] = forecast_date\n",
    "    predict['forecast_date'] = forecast_date\n",
    "    wh_train['forecast_date'] = forecast_date\n",
    "    wh_train_error['forecast_date'] = forecast_date\n",
    "    wh_predict['forecast_date'] = forecast_date\n",
    "\n",
    "    # SAFETY STOCK CALCULATIONS\n",
    "    last_actual_month = drug_sales_monthly['month_begin_dt'].max()\n",
    "    last_month_sales = drug_sales_monthly[\n",
    "        drug_sales_monthly['month_begin_dt'] == str(last_actual_month)]\n",
    "    last_month_sales = last_month_sales[['drug_id', 'net_sales_quantity']]\n",
    "    last_month_sales.rename(\n",
    "        columns={'net_sales_quantity': 'last_month_sales'}, inplace=True)\n",
    "    wh_safety_stock_df = wh_safety_stock_calc(\n",
    "        ss_runtime_var, wh_drug_list, wh_predict, last_month_sales, demand_daily_deviation, current_month_date,\n",
    "        forecast_date, reset_date, logger, expected_nso, nso_history_days, rs_db)\n",
    "    wh_safety_stock_df['wh_id'] = wh_id\n",
    "    wh_safety_stock_df['reset_date'] = str(reset_date)\n",
    "    rs_db.close_connection()\n",
    "\n",
    "    # WRITING TO POSTGRES\n",
    "    s3 = S3()\n",
    "    rs_db_write = DB(read_only=False)\n",
    "    rs_db_write.open_connection()\n",
    "\n",
    "    created_at = datetime.now(tz=gettz('Asia/Kolkata')).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    wh_safety_stock_df['ptr'] = ''\n",
    "    wh_safety_stock_df['fcst'] = wh_safety_stock_df['fcst'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['safety_stock'] = wh_safety_stock_df['safety_stock'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['month'] = wh_safety_stock_df['month'].astype(int)\n",
    "    wh_safety_stock_df['year'] = wh_safety_stock_df['year'].astype(int)\n",
    "    wh_safety_stock_df['ss_wo_cap'] = wh_safety_stock_df['ss_wo_cap'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['reorder_point'] = wh_safety_stock_df['reorder_point'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['order_upto_point'] = wh_safety_stock_df['order_upto_point'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['shelf_min'] = wh_safety_stock_df['shelf_min'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['shelf_max'] = wh_safety_stock_df['shelf_max'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['rop_without_nso'] = wh_safety_stock_df['rop_without_nso'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['oup_without_nso'] = wh_safety_stock_df['oup_without_nso'].fillna(0).astype(int)\n",
    "    wh_safety_stock_df['created_at'] = created_at\n",
    "    wh_safety_stock_df['created_by'] = 'etl-automation'\n",
    "    wh_safety_stock_df['updated_at'] = created_at\n",
    "    wh_safety_stock_df['updated_by'] = 'etl-automation'\n",
    "    columns = [c.replace('-', '_') for c in ['drug-id', 'drug-name', 'type', 'category', 'company', 'ptr', 'bucket',\n",
    "                                             'history-bucket', 'fcst', 'final-fcst', 'forecast-type', 'model',\n",
    "                                             'month', 'month-begin-dt', 'std', 'year', 'wh-id', 'forecast-date',\n",
    "                                             'lead-time-mean', 'lead-time-std', 'max-review-period',\n",
    "                                             'ordering-freq',\n",
    "                                             'service-level', 'z-value', 'demand-daily', 'demand-daily-deviation',\n",
    "                                             'safety-stock', 'launch-stock-per-store', 'expected-nso',\n",
    "                                             'rop-without-nso', 'reorder-point', 'oup-without-nso',\n",
    "                                             'order-upto-point', 'shelf-min', 'shelf-max', 'last-month-sales',\n",
    "                                             'safety-stock-days',\n",
    "                                             'reorder-point-days', 'order-upto-days', 'reset-date', 'created-at',\n",
    "                                             'created-by', 'updated-at', 'updated-by', 'cap_ss_days', 'ss_wo_cap']]\n",
    "    wh_safety_stock_df = wh_safety_stock_df[columns]\n",
    "\n",
    "    if debug_mode == 'N':\n",
    "        # drug_sales_monthly\n",
    "        drug_sales_monthly['created-at'] = created_at\n",
    "        drug_sales_monthly['created-by'] = 'etl-automation'\n",
    "        drug_sales_monthly['updated-at'] = created_at\n",
    "        drug_sales_monthly['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=drug_sales_monthly, table_name='wh-drug-sales-monthly', db=rs_db_write,\n",
    "                          schema='prod2-generico')\n",
    "\n",
    "        # train\n",
    "        train['type'] = 'separate'\n",
    "        train['created-at'] = created_at\n",
    "        train['created-by'] = 'etl-automation'\n",
    "        train['updated-at'] = created_at\n",
    "        train['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=train, table_name='wh-train', db=rs_db_write, schema='prod2-generico')\n",
    "\n",
    "        # wh_train\n",
    "        wh_train['type'] = 'ensemble'\n",
    "        wh_train['created-at'] = created_at\n",
    "        wh_train['created-by'] = 'etl-automation'\n",
    "        wh_train['updated-at'] = created_at\n",
    "        wh_train['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=wh_train, table_name='wh-train', db=rs_db_write, schema='prod2-generico')\n",
    "\n",
    "        # train_error\n",
    "        train_error['type'] = 'separate'\n",
    "        train_error['created-at'] = created_at\n",
    "        train_error['created-by'] = 'etl-automation'\n",
    "        train_error['updated-at'] = created_at\n",
    "        train_error['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=train_error, table_name='wh-train-error', db=rs_db_write, schema='prod2-generico')\n",
    "\n",
    "        # wh_train_error\n",
    "        wh_train_error['type'] = 'ensemble'\n",
    "        wh_train_error['created-at'] = created_at\n",
    "        wh_train_error['created-by'] = 'etl-automation'\n",
    "        wh_train_error['updated-at'] = created_at\n",
    "        wh_train_error['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=wh_train_error[train_error.columns], table_name='wh-train-error', db=rs_db_write,\n",
    "                          schema='prod2-generico')\n",
    "\n",
    "        # predict\n",
    "        predict['type'] = 'separate'\n",
    "        predict['created-at'] = created_at\n",
    "        predict['created-by'] = 'etl-automation'\n",
    "        predict['updated-at'] = created_at\n",
    "        predict['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=predict, table_name='wh-predict', db=rs_db_write, schema='prod2-generico')\n",
    "\n",
    "        # wh_predict\n",
    "        wh_predict['type'] = 'ensemble'\n",
    "        wh_predict['created-at'] = created_at\n",
    "        wh_predict['created-by'] = 'etl-automation'\n",
    "        wh_predict['updated-at'] = created_at\n",
    "        wh_predict['updated-by'] = 'etl-automation'\n",
    "        s3.write_df_to_db(df=wh_predict, table_name='wh-predict', db=rs_db_write, schema='prod2-generico')\n",
    "\n",
    "        # wh_safety_stock_df\n",
    "        s3.write_df_to_db(df=wh_safety_stock_df, table_name='wh-safety-stock', db=rs_db_write,\n",
    "                          schema='prod2-generico')\n",
    "    if reset == 'Y':\n",
    "        # UPLOADING SAFETY STOCK NUMBERS IN DRUG-ORDER-INFO\n",
    "        ss_data_upload = wh_safety_stock_df.query('order_upto_point > 0')[\n",
    "            ['wh_id', 'drug_id', 'safety_stock', 'reorder_point',\n",
    "             'order_upto_point']]\n",
    "        ss_data_upload.columns = [\n",
    "            'store_id', 'drug_id', 'corr_min', 'corr_ss', 'corr_max']\n",
    "        new_drug_entries, missed_entries = doid_update(\n",
    "            ss_data_upload, type_list, rs_db_write, schema, logger)\n",
    "        logger.info('DOI updated as per request')\n",
    "        logger.info('missed entries --> ' + str(missed_entries))\n",
    "        logger.info('new_drug_entries entries --> ' + str(new_drug_entries))\n",
    "    else:\n",
    "        logger.info('DOID did not update as per request')\n",
    "\n",
    "    rs_db_write.close_connection()\n",
    "    df_uri = s3.save_df_to_s3(df=wh_safety_stock_df,\n",
    "                              file_name='wh_safety_stock_{date}.csv'.format(date=str(forecast_date)))\n",
    "    status = True\n",
    "\n",
    "except Exception as error:\n",
    "    err_msg = str(error)\n",
    "    logger.info(str(error))\n",
    "    raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2857cfc-3e95-4522-a3bf-0416f9e8f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = Email()\n",
    "if debug_mode == 'Y':\n",
    "    email_to = 'vivek.sidagam@zeno.health,akshay.bhutada@zeno.health'\n",
    "\n",
    "if status:\n",
    "    result = 'Success'\n",
    "    email.send_email_file(subject=f\"Warehouse forecast & replenishment ({env}): {result}\",\n",
    "                          mail_body=f\"Run time: {datetime.now()} {err_msg}\",\n",
    "                          to_emails=email_to, file_uris=[df_uri])\n",
    "else:\n",
    "    result = 'Failed'\n",
    "    email.send_email_file(subject=f\"Warehouse forecast & replenishment ({env}): {result}\",\n",
    "                          mail_body=f\"Run time: {datetime.now()} {err_msg}\",\n",
    "                          to_emails=email_to, file_uris=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
