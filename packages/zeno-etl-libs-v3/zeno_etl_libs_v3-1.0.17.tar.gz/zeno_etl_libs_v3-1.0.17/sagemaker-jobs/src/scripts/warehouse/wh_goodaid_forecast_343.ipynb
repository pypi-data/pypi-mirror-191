{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f7a82-be9c-4423-a493-5f56074850ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install zeno_etl_libs_v3==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deab218-ef7c-431e-a549-8d1d21628ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun May 1 23:28:09 2021\n",
    "\n",
    "@author: vivek.sidagam@zeno.health\n",
    "\n",
    "Purpose: To generate forecast for Goodaid drugs at Goodaid warehouse\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from dateutil.tz import gettz\n",
    "\n",
    "sys.path.append('../../../..')\n",
    "\n",
    "from zeno_etl_libs.db.db import DB\n",
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.helper.email.email import Email\n",
    "from zeno_etl_libs.utils.ipc.doid_update_ss import doid_update\n",
    "from zeno_etl_libs.helper.parameter.job_parameter import parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d5a0f-3526-4f1b-bc36-d925f6113a99",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#tag = parameters\n",
    "env = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300fd401-eda2-4397-b196-5cc54db3b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['env'] = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43da48-d0e4-4787-8879-ec1e7f64ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = parameter.get_params(job_id=125)\n",
    "email_to = job_params['email_to']\n",
    "\n",
    "logger = get_logger()\n",
    "logger.info(\"Scripts begins. Env = \" + env)\n",
    "\n",
    "status = False\n",
    "err_msg = ''\n",
    "df_uri = ''\n",
    "run_date = str(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "drugs_not_in_doi = 0\n",
    "drugs_missed = 0\n",
    "drugs_updated = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779f934-3d4b-4df2-bf51-0702cb55e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rs_db = DB()\n",
    "    rs_db.open_connection()\n",
    "    # read inputs file to get parameters\n",
    "    logger.info('reading input file to get parameters')\n",
    "    params_table_query = \"\"\"\n",
    "        select\n",
    "            \"param-name\" as param,\n",
    "            value\n",
    "        from\n",
    "            \"prod2-generico\".\"wh-goodaid-forecast-input\"\n",
    "        where\n",
    "            \"param-name\" not in ('drug_lvl_fcst_inputs' , 's_and_op_factors')\n",
    "    \"\"\"\n",
    "    logger.info('input parameters read')\n",
    "    params_table = rs_db.get_df(params_table_query)\n",
    "    params_table = params_table.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    days = int(params_table.where(params_table['param'] == 'days',\n",
    "                                  axis=0).dropna()['value'])\n",
    "    expected_new_stores = int(params_table.where(\n",
    "        params_table['param'] == 'expected_new_stores',\n",
    "        axis=0).dropna()['value'])\n",
    "    wh_id = int(params_table.where(params_table['param'] == 'gaw_id',\n",
    "                                   axis=0).dropna()['value'])\n",
    "    revenue_min = int(params_table.where(\n",
    "        params_table['param'] == 'revenue_min', axis=0).dropna()['value'])\n",
    "    revenue_max = int(params_table.where(\n",
    "        params_table['param'] == 'revenue_max', axis=0).dropna()['value'])\n",
    "\n",
    "    # get active gaid drugs list\n",
    "\n",
    "    drugs_query = '''\n",
    "        select\n",
    "            wssm.\"drug-id\" as drug_id,\n",
    "            d.composition,\n",
    "            d.\"drug-name\" as drug_name,\n",
    "            d.company,\n",
    "            d.\"type\",\n",
    "            d.category\n",
    "        from\n",
    "            \"prod2-generico\".\"wh-sku-subs-master\" wssm\n",
    "        left join \"prod2-generico\".drugs d on\n",
    "            d.id = wssm.\"drug-id\"\n",
    "        where\n",
    "            wssm.\"add-wh\" = 'Yes'\n",
    "            and d.\"type\" not in ('discontinued-products')\n",
    "            and d.company = 'GOODAID'\n",
    "        '''\n",
    "    drugs = rs_db.get_df(drugs_query)\n",
    "    logger.info('active drugs list pulled from wssm')\n",
    "\n",
    "    # get 28 days sales for active gaid drugs\n",
    "    drug_sales_query = '''\n",
    "        select\n",
    "            \"drug-id\" as drug_id,\n",
    "            sum(quantity) as drug_sales_quantity\n",
    "        from\n",
    "            \"prod2-generico\".sales\n",
    "        where\n",
    "            \"drug-id\" in {drug_ids}\n",
    "            and date(\"created-at\") >= current_date - {days}\n",
    "            and date(\"created-at\") < current_date\n",
    "        group by\n",
    "            \"drug-id\"\n",
    "    '''.format(days=days, drug_ids=tuple(drugs['drug_id']))\n",
    "    drug_sales = rs_db.get_df(drug_sales_query)\n",
    "    logger.info('drug sales data pulled from rs')\n",
    "    drug_sales['drug_sales_quantity'] = drug_sales[\n",
    "                                            'drug_sales_quantity'] * 28 / days\n",
    "\n",
    "    # get non-ethical composition level sale\n",
    "    composition_sales_query = '''\n",
    "        select\n",
    "            composition as composition,\n",
    "            sum(quantity) as composition_sales_quantity\n",
    "        from\n",
    "            \"prod2-generico\".sales\n",
    "        where\n",
    "            composition in {compositions}\n",
    "            and date(\"created-at\") >= current_date - {days}\n",
    "            and date(\"created-at\") < current_date\n",
    "            and \"type\" <> 'ethical'\n",
    "        group by\n",
    "            composition\n",
    "    '''.format(days=days, compositions=tuple(drugs['composition']))\n",
    "    composition_sales = rs_db.get_df(composition_sales_query)\n",
    "    logger.info('composition data pulled from rs')\n",
    "    composition_sales['composition_sales_quantity'] = composition_sales[\n",
    "                                                          'composition_sales_quantity'] * 28 / days\n",
    "\n",
    "    # merging data\n",
    "    main_df = drugs.merge(drug_sales, on='drug_id', how='left')\n",
    "    main_df['drug_sales_quantity'].fillna(0, inplace=True)\n",
    "    main_df = main_df.merge(composition_sales, on='composition',\n",
    "                            how='left')\n",
    "    main_df['composition_sales_quantity'].fillna(0, inplace=True)\n",
    "\n",
    "    # getting 50% of composition level sales\n",
    "    main_df['composition_sales_quantity_50%'] = main_df[\n",
    "                                                    'composition_sales_quantity'] * 0.5\n",
    "    main_df['composition_sales_quantity_50%'] = main_df[\n",
    "        'composition_sales_quantity_50%'].round(0)\n",
    "\n",
    "    # calculate month-on-month sales growth\n",
    "    # getting last-to-last 28 day sales for calcuating growth factor\n",
    "    last_to_last_sales_query = '''\n",
    "        select\n",
    "            \"drug-id\" as drug_id,\n",
    "            sum(quantity) as last_to_last_28_day_sales\n",
    "        from\n",
    "            \"prod2-generico\".sales\n",
    "        where\n",
    "            \"drug-id\" in {drug_ids}\n",
    "            and date(\"created-at\") >= current_date - 56\n",
    "            and date(\"created-at\") < current_date - 28\n",
    "        group by\n",
    "            \"drug-id\"\n",
    "    '''.format(drug_ids=tuple(drugs['drug_id']))\n",
    "    last_to_last_sales = rs_db.get_df(last_to_last_sales_query)\n",
    "    logger.info('last-to-last 28 day sales data pulled from rs')\n",
    "\n",
    "    # getting last 28 day sales\n",
    "    last_sales_query = '''\n",
    "        select\n",
    "            \"drug-id\" as drug_id,\n",
    "            sum(quantity) as last_28_day_sales\n",
    "        from\n",
    "            \"prod2-generico\".sales\n",
    "        where\n",
    "            \"drug-id\" in {drug_ids}\n",
    "            and date(\"created-at\") >= current_date - 28\n",
    "            and date(\"created-at\") < current_date\n",
    "        group by\n",
    "            \"drug-id\"\n",
    "    '''.format(drug_ids=tuple(drugs['drug_id']))\n",
    "    last_sales = rs_db.get_df(last_sales_query)\n",
    "    logger.info('last 28 day sales data pulled from rs')\n",
    "\n",
    "    # merging to main_df\n",
    "    main_df = main_df.merge(last_to_last_sales, on='drug_id', how='left')\n",
    "    main_df['last_to_last_28_day_sales'].fillna(0, inplace=True)\n",
    "    main_df = main_df.merge(last_sales, on='drug_id', how='left')\n",
    "    main_df['last_28_day_sales'].fillna(0, inplace=True)\n",
    "    main_df['growth_factor'] = main_df['last_28_day_sales'] / main_df[\n",
    "        'last_to_last_28_day_sales']\n",
    "    main_df['growth_factor'].fillna(1, inplace=True)\n",
    "    main_df['growth_factor'] = np.where(main_df[\n",
    "                                            'growth_factor'] == np.inf, 1,\n",
    "                                        main_df['growth_factor'])\n",
    "    # growth factor capped at 150% - min at 100%\n",
    "    main_df['growth_factor'] = np.where(main_df[\n",
    "                                            'growth_factor'] > 1.5, 1.5,\n",
    "                                        main_df['growth_factor'])\n",
    "    main_df['growth_factor'] = np.where(main_df[\n",
    "                                            'growth_factor'] < 1, 1,\n",
    "                                        main_df['growth_factor'])\n",
    "    # growth factor foreced to 1 when 50% comp sales > drug sales\n",
    "    main_df['growth_factor'] = np.where(main_df[\n",
    "                                            'composition_sales_quantity_50%'] >\n",
    "                                        main_df[\n",
    "                                            'drug_sales_quantity'], 1,\n",
    "                                        main_df['growth_factor'])\n",
    "\n",
    "    # get s&op factor\n",
    "    logger.info('reading s&op factors table')\n",
    "    input_table_query = \"\"\"\n",
    "        select\n",
    "            \"drug-id\" as drug_id,\n",
    "            value as s_op_factor,\n",
    "            \"start-date\" as start_date,\n",
    "            \"end-date\" as end_date\n",
    "        from\n",
    "            \"prod2-generico\".\"wh-goodaid-forecast-input\"\n",
    "        where\n",
    "            \"param-name\" = 's_and_op_factors'  \n",
    "    \"\"\"\n",
    "    s_op_table = rs_db.get_df(input_table_query)\n",
    "    logger.info('s&op factors table read')\n",
    "    s_op_table = s_op_table.apply(pd.to_numeric, errors='ignore')\n",
    "    s_op_table = s_op_table[\n",
    "        s_op_table['start_date'] <= datetime.now().date()]\n",
    "    s_op_table = s_op_table[\n",
    "        s_op_table['end_date'] >= datetime.now().date()]\n",
    "    s_op_table.drop('start_date', axis=1, inplace=True)\n",
    "    s_op_table.drop('end_date', axis=1, inplace=True)\n",
    "    main_df = main_df.merge(s_op_table, on='drug_id', how='left')\n",
    "    main_df['s_op_factor'].fillna(1, inplace=True)\n",
    "\n",
    "    # get avg gaid sales for 13-16 lakh revenue stores\n",
    "    # getting stores lists to compare with\n",
    "    stores_cmp_query = '''\n",
    "        select\n",
    "            \"store-id\" as store_id,\n",
    "            round(sum(\"revenue-value\")) as revenue\n",
    "        from\n",
    "            \"prod2-generico\".sales\n",
    "        where\n",
    "            date(\"created-at\") >= current_date - 28\n",
    "            and date(\"created-at\") < current_date\n",
    "        group by\n",
    "            \"store-id\"\n",
    "    '''\n",
    "    stores_cmp = rs_db.get_df(stores_cmp_query)\n",
    "    stores_cmp = stores_cmp[stores_cmp['revenue'] > revenue_min]\n",
    "    stores_cmp = stores_cmp[stores_cmp['revenue'] < revenue_max]\n",
    "    stores_list_to_comp = tuple(stores_cmp['store_id'])\n",
    "    logger.info('list of stores with revenue between 1.3 and 1.6 mil -->'\n",
    "                + str(stores_list_to_comp))\n",
    "\n",
    "    # adding expected_new_stores column\n",
    "    main_df['expected_new_stores'] = expected_new_stores\n",
    "\n",
    "    # getting avg sales\n",
    "    avg_store_sales_query = '''\n",
    "        select\n",
    "            composition ,\n",
    "            sum(quantity)/ {count} as avg_drug_sales_quantity\n",
    "        from\n",
    "            \"prod2-generico\".sales\n",
    "        where\n",
    "            composition in {compositions}\n",
    "            and date(\"created-at\") >= current_date - 28\n",
    "            and date(\"created-at\") < current_date\n",
    "            and \"type\" <> 'ethical'\n",
    "            and \"store-id\" in {stores_list_to_comp}\n",
    "        group by\n",
    "            composition\n",
    "    '''.format(compositions=tuple(drugs['composition']), \\\n",
    "               stores_list_to_comp=stores_list_to_comp, \\\n",
    "               count=len(stores_list_to_comp))\n",
    "    avg_store_sales = rs_db.get_df(avg_store_sales_query)\n",
    "    logger.info('avg composition sales retrieved for sample stores')\n",
    "    avg_store_sales['avg_drug_sales_quantity'] = avg_store_sales[\n",
    "        'avg_drug_sales_quantity'].round()\n",
    "\n",
    "    # merge to main_df\n",
    "    main_df = main_df.merge(avg_store_sales, on='composition', how='left')\n",
    "    main_df['avg_drug_sales_quantity'].fillna(0, inplace=True)\n",
    "\n",
    "    # get final forecast figures\n",
    "    main_df['forecast'] = main_df[[\n",
    "        'drug_sales_quantity',\n",
    "        'composition_sales_quantity_50%']].max(axis=1)\n",
    "    main_df['forecast'] = main_df['forecast'] * main_df['growth_factor'] * \\\n",
    "                          main_df['s_op_factor'] + main_df[\n",
    "                              'expected_new_stores'] * \\\n",
    "                          main_df['avg_drug_sales_quantity']\n",
    "    main_df['forecast'] = main_df['forecast'].round()\n",
    "\n",
    "    # get input table and merge with main_df\n",
    "    logger.info('reading input table')\n",
    "    input_table_query = \"\"\"\n",
    "        select\n",
    "            \"drug-id\" as drug_id,\n",
    "            lead_time_doh,\n",
    "            safety_stock_doh,\n",
    "            review_period\n",
    "        from\n",
    "            \"prod2-generico\".\"wh-goodaid-forecast-input\"\n",
    "        where\n",
    "            \"param-name\" = 'drug_lvl_fcst_inputs'\n",
    "    \"\"\"\n",
    "    input_table = rs_db.get_df(input_table_query)\n",
    "    logger.info('input table read')\n",
    "    input_table = input_table.apply(pd.to_numeric, errors='ignore')\n",
    "    input_table['reorder_point_doh'] = input_table['lead_time_doh'] + \\\n",
    "                                       input_table['safety_stock_doh']\n",
    "    input_table['min_doh'] = input_table['safety_stock_doh']\n",
    "    input_table['order_upto_point_doh'] = input_table['lead_time_doh'] + \\\n",
    "                                          input_table['safety_stock_doh'] + \\\n",
    "                                          input_table['review_period']\n",
    "    main_df = main_df.merge(input_table, on='drug_id', how='left')\n",
    "\n",
    "    # populating missing rows with defaults\n",
    "    main_df['lead_time_doh'].fillna(\n",
    "        input_table.loc[input_table['drug_id'] == 0,\n",
    "                        'lead_time_doh'].item(), inplace=True)\n",
    "    main_df['safety_stock_doh'].fillna(\n",
    "        input_table.loc[input_table['drug_id'] == 0,\n",
    "                        'safety_stock_doh'].item(), inplace=True)\n",
    "    main_df['review_period'].fillna(\n",
    "        input_table.loc[input_table['drug_id'] == 0,\n",
    "                        'review_period'].item(), inplace=True)\n",
    "    main_df['reorder_point_doh'].fillna(\n",
    "        input_table.loc[input_table['drug_id'] == 0,\n",
    "                        'reorder_point_doh'].item(), inplace=True)\n",
    "    main_df['min_doh'].fillna(\n",
    "        input_table.loc[input_table['drug_id'] == 0,\n",
    "                        'min_doh'].item(), inplace=True)\n",
    "    main_df['order_upto_point_doh'].fillna(\n",
    "        input_table.loc[input_table['drug_id'] == 0,\n",
    "                        'order_upto_point_doh'].item(), inplace=True)\n",
    "\n",
    "    # calculate ss min max\n",
    "    main_df['safety_stock'] = (main_df['forecast'] / 28 *\n",
    "                               main_df['safety_stock_doh']).round()\n",
    "    main_df['reorder_point'] = (main_df['forecast'] / 28 *\n",
    "                                main_df['reorder_point_doh']).round()\n",
    "    main_df['order_upto_point'] = (main_df['forecast'] / 28 *\n",
    "                                   main_df['order_upto_point_doh']).round()\n",
    "\n",
    "    # get table structure to write to\n",
    "    to_upload_query = '''\n",
    "        select\n",
    "            *\n",
    "        from\n",
    "            \"prod2-generico\".\"wh-safety-stock\"\n",
    "        limit 1\n",
    "    '''\n",
    "    to_upload = rs_db.get_df(to_upload_query)\n",
    "    to_upload.columns = [c.replace('-', '_') for c in to_upload.columns]\n",
    "\n",
    "    to_upload.drop(0, axis=0, inplace=True)\n",
    "\n",
    "    to_upload['drug_id'] = main_df['drug_id']\n",
    "    to_upload['drug_name'] = main_df['drug_name']\n",
    "    to_upload['type'] = main_df['type']\n",
    "    to_upload['category'] = main_df['category']\n",
    "    to_upload['company'] = main_df['company']\n",
    "    # to_upload['bucket'] = main_df['bucket']\n",
    "    to_upload['fcst'] = main_df['forecast'].astype(int, errors='ignore')\n",
    "    to_upload['wh_id'] = wh_id\n",
    "    to_upload['forecast_type'] = 'goodaid'\n",
    "    to_upload['lead_time_mean'] = main_df['lead_time_doh']\n",
    "    to_upload['max_review_period'] = main_df['review_period'].astype(int, errors='ignore')\n",
    "    to_upload['demand_daily'] = main_df['forecast'] / 28\n",
    "    to_upload['safety_stock'] = main_df['safety_stock'].astype(int, errors='ignore')\n",
    "    to_upload['expected_nso'] = expected_new_stores\n",
    "    to_upload['reorder_point'] = main_df['reorder_point'].astype(int, errors='ignore')\n",
    "    to_upload['order_upto_point'] = main_df['order_upto_point'].astype(int, errors='ignore')\n",
    "    to_upload['last_month_sales'] = main_df['drug_sales_quantity'].astype(int, errors='ignore')\n",
    "    to_upload['safety_stock_days'] = main_df['safety_stock_doh']\n",
    "    to_upload['reorder_point_days'] = main_df['reorder_point_doh']\n",
    "    to_upload['order_upto_days'] = main_df['order_upto_point_doh']\n",
    "    to_upload['reset_date'] = run_date\n",
    "    to_upload['month'] = str(datetime.now(tz=gettz('Asia/Kolkata')).strftime(\"%m\"))\n",
    "    to_upload['year'] = str(datetime.now(tz=gettz('Asia/Kolkata')).strftime(\"%Y\"))\n",
    "    to_upload['month_begin_dt'] = str(\n",
    "        datetime.now(tz=gettz('Asia/Kolkata')).date() - timedelta(days=datetime.now(tz=gettz('Asia/Kolkata')).day - 1))\n",
    "    to_upload['created_at'] = datetime.now(tz=gettz('Asia/Kolkata')).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    to_upload['created_by'] = 'etl-automation'\n",
    "    to_upload['updated_at'] = datetime.now(tz=gettz('Asia/Kolkata')).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    to_upload['updated_by'] = 'etl-automation'\n",
    "    to_upload = to_upload.fillna('')\n",
    "    rs_db_write = DB(read_only=False)\n",
    "    rs_db_write.open_connection()\n",
    "    s3 = S3()\n",
    "    s3.write_df_to_db(df=to_upload, table_name='wh-safety-stock',\n",
    "                      db=rs_db_write, schema='prod2-generico')\n",
    "    logger.info(\"wh-safety-stock table updated\")\n",
    "\n",
    "    # WRITING ATTACHMENTS FOR SUCCESS\n",
    "    df_uri = s3.save_df_to_s3(df=main_df,\n",
    "                              file_name='GAW_goodaid_forecast_{date}.csv'.format(date=str(run_date)))\n",
    "\n",
    "    # writing to doid\n",
    "    logger.info('writing to doid for ' +\n",
    "                str(int(to_upload[['drug_id']].nunique())) + ' drugs')\n",
    "    ss_data_upload = to_upload.query('order_upto_point > 0')[\n",
    "        ['wh_id', 'drug_id', 'safety_stock', 'reorder_point',\n",
    "         'order_upto_point']]\n",
    "    ss_data_upload.columns = [\n",
    "        'store_id', 'drug_id', 'corr_min', 'corr_ss', 'corr_max']\n",
    "    type_list = tuple(drugs['type'].unique())\n",
    "    ss_data_upload = ss_data_upload.astype(float)\n",
    "    new_drug_entries, missed_entries = doid_update(\n",
    "        ss_data_upload, type_list, rs_db, 'prod2-generico', logger, gaid_omit=False)\n",
    "    rs_db.connection.close()\n",
    "    drugs_not_in_doi = len(new_drug_entries)\n",
    "    drugs_missed = len(missed_entries)\n",
    "    drugs_updated = len(ss_data_upload) - len(missed_entries) - len(new_drug_entries)\n",
    "    rs_db.close_connection()\n",
    "    rs_db_write.close_connection()\n",
    "    status = True\n",
    "\n",
    "except Exception as e:\n",
    "    err_msg = str(e)\n",
    "    logger.info('wh_goodaid_forecast_343 job failed')\n",
    "    logger.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bf67a-65bf-431a-a590-5141cc25d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending email\n",
    "email = Email()\n",
    "if status:\n",
    "    result = 'Success'\n",
    "    email.send_email_file(subject=f\"GOODAID Warehouse forecast ({env}): {result}\",\n",
    "                          mail_body=f\"\"\"\n",
    "                            drugs updated successfully --> {drugs_updated}\n",
    "                            drugs not updated --> {drugs_missed}\n",
    "                            drugs not in doid --> {drugs_not_in_doi}\n",
    "                          \"\"\",\n",
    "                          to_emails=email_to, file_uris=[df_uri])\n",
    "else:\n",
    "    result = 'Failed'\n",
    "    email.send_email_file(subject=f\"GOODAID Warehouse forecast ({env}): {result}\",\n",
    "                          mail_body=f\"Run time: {datetime.now(tz=gettz('Asia/Kolkata'))} {err_msg}\",\n",
    "                          to_emails=email_to, file_uris=[])\n",
    "\n",
    "logger.info(\"Script ended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
