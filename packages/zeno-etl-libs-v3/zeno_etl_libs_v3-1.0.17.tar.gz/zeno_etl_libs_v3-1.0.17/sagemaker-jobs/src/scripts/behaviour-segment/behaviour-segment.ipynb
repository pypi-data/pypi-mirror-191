{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandasql\n",
    "!pip install zeno_etl_libs==1.0.31\n",
    "!pip install pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa837335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Author - shubham.jangir@zeno.health, shubham.gupta@zeno.health \n",
    "# Purpose - script with DSS write action for customer behaviour (transactional) segment\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42373605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.db.db import DB\n",
    "from zeno_etl_libs.helper import helper\n",
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.helper.email.email import Email\n",
    "\n",
    "from datetime import datetime as dt, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import pandasql as ps\n",
    "\n",
    "from dateutil.tz import gettz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation (Standardization)\n",
    "def standardize(x_var, mean_x, std_x):\n",
    "    \"\"\"\n",
    "    Standardizing 'x' variable by it's mean and std provided\n",
    "    \"\"\"\n",
    "    return (x_var - mean_x) / std_x\n",
    "\n",
    "\n",
    "def cluster_predict(data_matrix, centroids):\n",
    "    \"\"\"\n",
    "    Predict cluster number, from data matrix given\n",
    "    And centroids given\n",
    "    Just find nearest cluster for each data point\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    for unit in data_matrix:\n",
    "        distances = []\n",
    "        for center in centroids:\n",
    "            dist = np.sum((unit - center) ** 2)\n",
    "            # print(dist)\n",
    "            distances.append(dist)\n",
    "        # print(distances)\n",
    "        closest_centroid = np.argmin(distances)\n",
    "        # print(closest_centroid)\n",
    "        clusters.append(closest_centroid)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfeff7e",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "env = \"dev\"\n",
    "email_to = [\"shubham.jangir@zeno.health\", \"shubham.gupta@zeno.health\"]\n",
    "period_end_d_plus1 = \"0\"\n",
    "schema = \"public\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad6696-f56e-408f-98f9-c3d27306cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['env'] = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a00bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b248b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"env: {env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31da7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'customer-behaviour-segment'\n",
    "\n",
    "rs_db = DB()\n",
    "rs_db.open_connection()\n",
    "\n",
    "s3 = S3(bucket_name='datascience-manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ee920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seek():\n",
    "    \"\"\" get the data \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf33e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fun(rs_db, s3):\n",
    "    # write logic here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddfe46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = helper.get_table_info(db=rs_db, table_name=table_name, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment calculation date can either be fetched from db manager or from run-date    \n",
    "# Segment calculation date should be 1st of every month\n",
    "\n",
    "try:\n",
    "    period_end_d_plus1 = str(dt.strptime(period_end_d_plus1, \"%Y-%m-%d\").date())\n",
    "    period_end_d_plus1 = period_end_d_plus1[:-3] + '-01'\n",
    "except ValueError:\n",
    "    period_end_d_plus1 = dt.today().strftime('%Y-%m') + '-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cba66e-5350-4472-ae52-b2592d6fa74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_schema = 'prod2-generico'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd76a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_year_month = dt.strptime(period_end_d_plus1, \"%Y-%m-%d\").strftime(\"%Y_%b\")\n",
    "\n",
    "# Period start date\n",
    "period_start_d_ts = dt.strptime(period_end_d_plus1, '%Y-%m-%d') - timedelta(days=180)\n",
    "period_start_d = period_start_d_ts.strftime('%Y-%m-%d')\n",
    "\n",
    "# Period end date\n",
    "period_end_d_ts = dt.strptime(period_end_d_plus1, '%Y-%m-%d') - timedelta(days=1)\n",
    "period_end_d = period_end_d_ts.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474c06b-92df-49f7-9d65-51ed4c52807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Patients and bills in last 6 months\n",
    "###################################################\n",
    "\n",
    "data_q = f\"\"\"\n",
    "            select\n",
    "                s.\"patient-id\",\n",
    "                count(distinct s.\"bill-id\") as \"num-bills-period\",\n",
    "                min(date(s.\"created-at\")) as \"first-time-in-period\",\n",
    "                max(date(s.\"created-at\")) as \"last-time-in-period\",\n",
    "                count(distinct date(s.\"created-at\")) as \"num-days-visited\",\n",
    "                sum(s.quantity) as \"total-quantity-period\",\n",
    "                sum(s.\"revenue-value\") as \"total-spend-period\",\n",
    "                sum(case when s.\"type\" in ('ethical', 'high-value-ethical') then quantity else 0 end) as \"quantity-ethical\",\n",
    "                sum(case when s.\"type\" in ('generic', 'high-value-generic') then quantity else 0 end) as \"quantity-generic\",\n",
    "                sum(case when s.\"type\" = 'surgical' then quantity else 0 end) as \"quantity-surgical\",\n",
    "                sum(case when s.\"type\" = 'ayurvedic' then quantity else 0 end) as \"quantity-ayurvedic\",\n",
    "                sum(case when s.\"type\" = 'general' then quantity else 0 end) as \"quantity-general\",\n",
    "                sum(case when s.\"type\" = 'otc' then quantity else 0 end) as \"quantity-otc\",\n",
    "                sum(case when s.\"category\" = 'chronic' then quantity else 0 end) as \"quantity-chronic\",\n",
    "                min(pm.\"first-bill-date\") as \"overall-min-bill-date\",\n",
    "                min(pm.\"hd-min-bill-date\") as \"min-hd-creation-date\"\n",
    "            from\n",
    "                \"{read_schema}\".sales s\n",
    "            left join \"{read_schema}\".\"patients-metadata-2\" pm on\n",
    "                s.\"patient-id\" = pm.id\n",
    "            where\n",
    "                DATE(s.\"created-at\") between '{period_start_d}' and '{period_end_d}'\n",
    "                and s.\"bill-flag\" = 'gross'\n",
    "            group by\n",
    "                s.\"patient-id\";        \n",
    "            \"\"\"\n",
    "\n",
    "bill_data = rs_db.get_df(query=data_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57cb27-6f9a-473a-8dce-ff791e20534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"fetched data - data-type {bill_data.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717e200-bbda-4876-bd20-301aea3c986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_data['first-time-in-period'] = pd.to_datetime(bill_data['first-time-in-period'])\n",
    "bill_data['last-time-in-period'] = pd.to_datetime(bill_data['last-time-in-period'])\n",
    "bill_data['total-spend-period'] = bill_data['total-spend-period'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29901b35-52d1-436f-8716-66ac4f104d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_data[(bill_data['quantity-generic']==0)].sort_values('num-days-visited', ascending=False).head()\n",
    "\n",
    "#26455527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################\n",
    "# # Bill level summary\n",
    "# ###################################################\n",
    "# bill_summ_q = \"\"\"\n",
    "#     SELECT\n",
    "#         `bill-id`,\n",
    "#         `patient-id`,\n",
    "#         `bill-date`,\n",
    "#         SUM(quantity) AS `total-quantity-bill`,\n",
    "#         SUM(rate*quantity) AS `total-spend-bill`,\n",
    "#         SUM(CASE\n",
    "#                 WHEN `drug-type` IN ('ethical','high-value-ethical') THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-ethical`,\n",
    "#         SUM(CASE\n",
    "#                 WHEN `drug-type` IN ('generic','high-value-generic') THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-generic`,\n",
    "#         SUM(CASE\n",
    "#                 WHEN `drug-type` = 'surgical' THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-surgical`,\n",
    "#         SUM(CASE\n",
    "#                 when `drug-type` = 'ayurvedic' THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-ayurvedic`,\n",
    "#         SUM(CASE\n",
    "#                 WHEN `drug-type` = 'general' THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-general`,\n",
    "#         SUM(CASE\n",
    "#                 WHEN `drug-type` = 'otc' THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-otc`,\n",
    "#         SUM(CASE\n",
    "#                 WHEN `drug-category` = 'chronic' THEN quantity\n",
    "#                 ELSE 0\n",
    "#             END) AS `quantity-chronic`\n",
    "#     FROM\n",
    "#         data\n",
    "#     GROUP BY\n",
    "#         `bill-id`,\n",
    "#         `patient-id`,\n",
    "#         `bill-date`\n",
    "#         \"\"\"\n",
    "# bill_grp = ps.sqldf(bill_summ_q, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################\n",
    "# # Patient level grouping\n",
    "# ###################################################\n",
    "# patient_summ_q = \"\"\"\n",
    "#     SELECT\n",
    "#         `patient-id`,\n",
    "#         COUNT(distinct `bill-id`) AS `num-bills-period`,\n",
    "#         MIN(`bill-date`) AS `first-time-in-period`,\n",
    "#         MAX(`bill-date`) AS `last-time-in-period`,\n",
    "#         COUNT(DISTINCT `bill-date`) AS `num-days-visited`,\n",
    "#         SUM(`total-quantity-bill`) AS `total-quantity-period`,\n",
    "#         SUM(`total-spend-bill`) AS `total-spend-period`,\n",
    "#         SUM(`quantity-ethical`) AS `quantity-ethical`,\n",
    "#         SUM(`quantity-generic`) AS `quantity-generic`,\n",
    "#         SUM(`quantity-surgical`) AS `quantity-surgical`,\n",
    "#         SUM(`quantity-ayurvedic`) AS `quantity-ayurvedic`,\n",
    "#         SUM(`quantity-general`) AS `quantity-general`,\n",
    "#         SUM(`quantity-otc`) AS `quantity-otc`,\n",
    "#         SUM(`quantity-chronic`) AS `quantity-chronic`\n",
    "#     FROM\n",
    "#         bill_grp\n",
    "#     GROUP BY\n",
    "#         `patient-id`\n",
    "#         \"\"\"\n",
    "# patient_level = ps.sqldf(patient_summ_q, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ced1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################\n",
    "# # Customer minimum bill date\n",
    "# ###################################################\n",
    "\n",
    "# acq_q = f\"\"\"\n",
    "#     SELECT\n",
    "#         \"patient-id\",\n",
    "#         MIN(DATE(\"created-at\")) AS \"overall-min-bill-date\"\n",
    "#     FROM\n",
    "#         \"{read_schema}\".\"bills-1\"\n",
    "#     WHERE\n",
    "#         DATE(\"created-at\") <= '{period_end_d}'\n",
    "#     GROUP BY\n",
    "#         \"patient-id\"\n",
    "#         \"\"\"\n",
    "# data_cc = rs_db.get_df(query=acq_q)\n",
    "\n",
    "# data_cc['overall-min-bill-date'] = pd.to_datetime(data_cc['overall-min-bill-date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################\n",
    "# # HD customers\n",
    "# ###################################################\n",
    "\n",
    "# hd_q = f\"\"\"\n",
    "#     SELECT\n",
    "#         \"patient-id\",\n",
    "#         MIN(DATE(\"created-at\")) AS \"min-hd-creation-date\"\n",
    "#     FROM\n",
    "#         \"{read_schema}\".\"patients-store-orders\"\n",
    "#     WHERE\n",
    "#         \"order-type\" = 'delivery'\n",
    "#         and DATE(\"created-at\") <= '{period_end_d}'\n",
    "#     GROUP BY\n",
    "#         \"patient-id\"  \n",
    "# \"\"\"\n",
    "# data_hd = rs_db.get_df(query=hd_q)\n",
    "\n",
    "# data_hd['min-hd-creation-date'] = pd.to_datetime(data_hd['min-hd-creation-date'])\n",
    "\n",
    "# # Append this info\n",
    "# data_merge = patient_level.merge(data_cc, how='left', on=['patient-id', 'patient-id'])\n",
    "# data_merge = data_merge.merge(data_hd, how='left', on=['patient-id', 'patient-id'])\n",
    "\n",
    "# Change data-sets names\n",
    "data = bill_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e678e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for types_col in ['quantity-ethical', 'quantity-generic', 'quantity-surgical',\n",
    "#                   'quantity-ayurvedic', 'quantity-general', 'quantity-otc',\n",
    "#                   'quantity-chronic']: \n",
    "#     print(types_col + \"-pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Derived features\n",
    "###################################################\n",
    "data['spend-per-bill'] = np.round(data['total-spend-period'] / data['num-bills-period'], 2)\n",
    "data['units-per-bill'] = np.round(data['total-quantity-period'] / data['num-bills-period'], 2)\n",
    "\n",
    "data['total-interaction-period'] = (pd.to_datetime(data['last-time-in-period']).dt.normalize()\n",
    "                                    - pd.to_datetime(data['first-time-in-period']).dt.normalize()\n",
    "                                    ).dt.days\n",
    "data['avg-purchase-interval'] = data['total-interaction-period'] / (data['num-days-visited'] - 1)\n",
    "\n",
    "# Generico age is defined as last date in period, to date creation of customer\n",
    "data['generico-age-customer'] = (pd.to_datetime(data['last-time-in-period']).dt.normalize()\n",
    "                                 - pd.to_datetime(data['overall-min-bill-date']).dt.normalize()\n",
    "                                 ).dt.days\n",
    "data['recency-customer'] = (pd.to_datetime(period_end_d).normalize()\n",
    "                            - pd.to_datetime(data['last-time-in-period']).dt.normalize()\n",
    "                            ).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdfb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for types_col in ['quantity-ethical', 'quantity-generic', 'quantity-surgical',\n",
    "                  'quantity-ayurvedic', 'quantity-general', 'quantity-otc',\n",
    "                  'quantity-chronic']:\n",
    "    data[types_col + \"-pc\"] = data[types_col] / data['total-quantity-period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['chronic-yes'] = np.where(data['quantity-chronic-pc'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Remove outliers - custom defined as of now\n",
    "###################################################\n",
    "data_for_mean_std = data[data['units-per-bill'] <= 50]\n",
    "data_for_mean_std = data_for_mean_std[data_for_mean_std['spend-per-bill'] <= 10000]\n",
    "data_for_mean_std = data_for_mean_std[data_for_mean_std['num-days-visited'] <= 52]\n",
    "data_for_mean_std = data_for_mean_std[data_for_mean_std['num-bills-period'] <= 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Clustering is done for old repeat customers only, so\n",
    "###################################################\n",
    "old_c_period_end_d_ts = dt.strptime(period_end_d, '%Y-%m-%d') - timedelta(days=60)\n",
    "old_c_period_end_d = old_c_period_end_d_ts.strftime('%Y-%m-%d')\n",
    "\n",
    "data_for_mean_std = data_for_mean_std[\n",
    "    (pd.to_datetime(data_for_mean_std['overall-min-bill-date']) <= old_c_period_end_d) &\n",
    "    (data_for_mean_std['num-days-visited'] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['num-days-visited', 'spend-per-bill', 'units-per-bill',\n",
    "                 'total-interaction-period', 'avg-purchase-interval',\n",
    "                 'generico-age-customer', 'recency-customer',\n",
    "                 'quantity-ethical-pc', 'quantity-generic-pc',\n",
    "                 'quantity-surgical-pc', 'quantity-ayurvedic-pc',\n",
    "                 'quantity-general-pc', 'quantity-otc-pc', 'quantity-chronic-pc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names\n",
    "data_for_mean_std = data_for_mean_std[feature_names]\n",
    "\n",
    "# Save mean and sd\n",
    "mean_std_old_repeat_14f = pd.DataFrame(columns=['feature-name', 'mean', 'std'])\n",
    "mean_std_old_repeat_14f['feature-name'] = data_for_mean_std.columns\n",
    "for i in data_for_mean_std.columns:\n",
    "    data_i_mean = data_for_mean_std[i].mean()\n",
    "    data_i_std = data_for_mean_std[i].std()\n",
    "    mean_std_old_repeat_14f.loc[mean_std_old_repeat_14f['feature-name'] == i,\n",
    "                                'mean'] = data_i_mean\n",
    "    mean_std_old_repeat_14f.loc[mean_std_old_repeat_14f['feature-name'] == i,\n",
    "                                'std'] = data_i_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Pre-processing starts here\n",
    "###################################################\n",
    "# Extra info appended\n",
    "data['home-delivery-flag'] = np.where(data['min-hd-creation-date'] <= period_end_d,\n",
    "                                      'yes', 'no')\n",
    "\n",
    "# HD flag for summarization purpose\n",
    "data['hd-yes'] = np.where(data['home-delivery-flag'] == 'yes',\n",
    "                          1, 0)\n",
    "\n",
    "data['newcomer-flag'] = np.where(pd.to_datetime(data['overall-min-bill-date']) > old_c_period_end_d,\n",
    "                                 'newcomer', 'old_customer')\n",
    "data['singletripper-flag'] = np.where(data['num-days-visited'] == 1,\n",
    "                                      'singletripper', 'repeat_customer')\n",
    "\n",
    "data_superset = data.copy()\n",
    "\n",
    "data_old_repeat = data[\n",
    "    (data['newcomer-flag'] == 'old_customer') &\n",
    "    (data['singletripper-flag'] == 'repeat_customer')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as main data\n",
    "data = data_old_repeat.copy()\n",
    "data = data[feature_names]\n",
    "\n",
    "# Import mean and std per feature\n",
    "mean_std_features = mean_std_old_repeat_14f.copy()\n",
    "mean_std_features = mean_std_features[['feature-name', 'mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "for i in data.columns:\n",
    "    mean_i = list(mean_std_features.loc[mean_std_features['feature-name'] == i, 'mean'])[0]\n",
    "    std_i = list(mean_std_features.loc[mean_std_features['feature-name'] == i, 'std'])[0]\n",
    "    # Standardize\n",
    "    data[i + \"-norm\"] = standardize(data[i], mean_i, std_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428455ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only Standardized columns for modelling\n",
    "norm_cols = [i for i in data.columns if i.endswith(\"-norm\")]\n",
    "data = data[norm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec927945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PCA Components\n",
    "pca_components = pd.read_csv(s3.download_file_from_s3('data/Job-6/input/pca_repeat_14f_10pca_94pc_variance.csv'))\n",
    "pca_components.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to matrix form\n",
    "data_mat = np.array(data)\n",
    "# Convert PCA components to matrix form\n",
    "pca_mat = np.array(pca_components).T\n",
    "\n",
    "# Multiply data matrix to PCA matrix, to transform into PCA features\n",
    "data_to_pca = np.matmul(data_mat, pca_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99329fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans\n",
    "# centroids import\n",
    "kmeans_centroids = pd.read_csv(s3.download_file_from_s3('data/Job-6/input/kmeans_centroids_repeat_6c_14f_10pca.csv'))\n",
    "kmeans_centroids.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7eceb-702b-45e3-b113-d164cca82b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert centroids data-set to matrix form\n",
    "kmeans_centroids_mat = np.array(kmeans_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Predict\n",
    "###################################################\n",
    "# Predict cluster number\n",
    "cluster_no = cluster_predict(data_to_pca, kmeans_centroids_mat)\n",
    "\n",
    "# Back to pandas data-set\n",
    "data_final = data.copy()\n",
    "data_final['cluster'] = cluster_no\n",
    "\n",
    "data_merge = data_old_repeat.merge(data_final, how='inner', left_index=True,\n",
    "                                   right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To summarize on\n",
    "summary_cols_median = ['num-days-visited', 'spend-per-bill',\n",
    "                       'units-per-bill', 'total-interaction-period',\n",
    "                       'avg-purchase-interval', 'generico-age-customer',\n",
    "                       'recency-customer', 'quantity-ethical-pc',\n",
    "                       'quantity-generic-pc', 'quantity-chronic-pc',\n",
    "                       'total-spend-period']  # for info purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols_mean = summary_cols_median + ['chronic-yes', 'hd-yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_agg_dict = {'num-days-visited': ['count', 'median'],\n",
    "                   'spend-per-bill': 'median',\n",
    "                   'units-per-bill': 'median',\n",
    "                   'total-interaction-period': 'median',\n",
    "                   'avg-purchase-interval': 'median',\n",
    "                   'generico-age-customer': 'median',\n",
    "                   'recency-customer': 'median',\n",
    "                   'quantity-ethical-pc': 'median',\n",
    "                   'quantity-generic-pc': 'median',\n",
    "                   'quantity-chronic-pc': 'median',\n",
    "                   'total-spend-period': ['median', 'sum']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it re-usable later on\n",
    "mean_agg_dict = {'num-days-visited': ['count', 'mean'],\n",
    "                 'spend-per-bill': 'mean',\n",
    "                 'units-per-bill': 'mean',\n",
    "                 'total-interaction-period': 'mean',\n",
    "                 'avg-purchase-interval': 'mean',\n",
    "                 'generico-age-customer': 'mean',\n",
    "                 'recency-customer': 'mean',\n",
    "                 'quantity-ethical-pc': 'mean',\n",
    "                 'quantity-generic-pc': 'mean',\n",
    "                 'quantity-chronic-pc': 'mean',\n",
    "                 'total-spend-period': ['mean', 'sum'],\n",
    "                 'chronic-yes': 'mean',\n",
    "                 'hd-yes': 'mean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf14650",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Profile summary of clusters\n",
    "###################################################\n",
    "# Mean profile\n",
    "profile_data = data_merge[summary_cols_mean + ['cluster']].groupby(\n",
    "    ['cluster']).agg(mean_agg_dict)\n",
    "\n",
    "length_base_cluster = len(data_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16451740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_extra_cols(profile_data_pass, length_base_pass):\n",
    "    # Segment % share in data-set\n",
    "    profile_data_pass['count-pc'] = np.round(\n",
    "        profile_data_pass['num-days-visited']['count'] * 100 / length_base_pass)\n",
    "    # Round all numbers\n",
    "    profile_data_pass = np.round(profile_data_pass, 2)\n",
    "    return profile_data_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3787c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data = profile_extra_cols(profile_data, length_base_cluster)\n",
    "\n",
    "# Median profile\n",
    "profile_data_med = data_merge[summary_cols_median + ['cluster']].groupby(\n",
    "    ['cluster']).agg(median_agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data_med = profile_extra_cols(profile_data_med, length_base_cluster)\n",
    "\n",
    "# Save both profile summaries (mean and median) to .csv\n",
    "s3.save_df_to_s3(df=profile_data, \n",
    "                 file_name='Behaviour_Segment_Output/profile_data_{}.csv'.format(calc_year_month), \n",
    "                 index=False)\n",
    "\n",
    "s3.save_df_to_s3(df=profile_data_med, \n",
    "                 file_name='Behaviour_Segment_Output/profile_data_med_{}.csv'.format(calc_year_month), \n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Name clusters\n",
    "###################################################\n",
    "data_merge['cluster-name'] = data_merge['cluster'].map({0: 'generic_heavy',\n",
    "                                                        1: 'regular',\n",
    "                                                        3: 'super',\n",
    "                                                        5: 'ethical_heavy',\n",
    "                                                        2: 'other_type',\n",
    "                                                        4: 'other_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea642df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient_id wise, for all\n",
    "data_superset_merge = data_superset.merge(data_merge[['patient-id', 'cluster-name']],\n",
    "                                          how='left',\n",
    "                                          on=['patient-id', 'patient-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54591aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_extra_segment(data_pass):\n",
    "    \"\"\"\n",
    "    Add segment names to segments not covered in clustering\n",
    "    \"\"\"\n",
    "    if (data_pass['newcomer-flag'] == 'newcomer' and\n",
    "            data_pass['singletripper-flag'] == 'repeat_customer'):\n",
    "        return 'newcomer_repeat'\n",
    "    elif (data_pass['newcomer-flag'] == 'newcomer' and\n",
    "          data_pass['singletripper-flag'] == 'singletripper'):\n",
    "        return 'newcomer_singletripper'\n",
    "    elif (data_pass['newcomer-flag'] == 'old_customer' and\n",
    "          data_pass['singletripper-flag'] == 'singletripper'):\n",
    "        return 'singletripper'\n",
    "    else:\n",
    "        return data_pass['cluster-name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign segment names for extra segments\n",
    "data_superset_merge['behaviour-segment'] = data_superset_merge.apply(\n",
    "    lambda row: assign_extra_segment(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d46aa-f01c-4f30-92ce-4af136f45489",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_superset_merge.groupby('behaviour-segment', as_index=False)['patient-id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Profiling all segment (Summary statistics for information)\n",
    "###################################################\n",
    "# Mean profile\n",
    "profile_data_all = data_superset_merge[summary_cols_mean + ['behaviour-segment']].groupby(\n",
    "    ['behaviour-segment']).agg(mean_agg_dict)\n",
    "\n",
    "length_base_segment = len(data_superset_merge)\n",
    "\n",
    "profile_data_all = profile_extra_cols(profile_data_all, length_base_segment)\n",
    "\n",
    "# Median profile\n",
    "profile_data_med_all = data_superset_merge[summary_cols_median + ['behaviour-segment']].groupby(\n",
    "    ['behaviour-segment']).agg(median_agg_dict)\n",
    "\n",
    "profile_data_med_all = profile_extra_cols(profile_data_med_all, length_base_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both profile summaries (mean and median) to .csv\n",
    "profile_data_all = s3.save_df_to_s3(df=profile_data_all, \n",
    "                                    file_name='Behaviour_Segment_Output/profile_data_all_{}.csv'.format(calc_year_month), \n",
    "                                    index=False)\n",
    "\n",
    "profile_data_med_all =s3.save_df_to_s3(df=profile_data_med_all, \n",
    "                                       file_name='Behaviour_Segment_Output/profile_data_med_all_{}.csv'.format(calc_year_month), \n",
    "                                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .csv, the profile summary of each segment\n",
    "\n",
    "for i in data_superset_merge['behaviour-segment'].unique():\n",
    "    segment_i = data_superset_merge[data_superset_merge['behaviour-segment'] == i]\n",
    "    logger.info(f'Length of {i} segment is {len(segment_i)}')\n",
    "    # Summarize\n",
    "    profile_i = segment_i[summary_cols_mean].describe()\n",
    "    s3.save_df_to_s3(df=profile_i, \n",
    "                 file_name='profile_{}.csv'.format(i), \n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38618ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this data is source of truth\n",
    "data = data_superset_merge.copy()\n",
    "\n",
    "###################################################\n",
    "# Assign unique store to patient\n",
    "###################################################\n",
    "\n",
    "patient_store_q = f\"\"\"\n",
    "                    select\n",
    "                        pm.id as \"patient-id\",\n",
    "                        \"primary-store-id\" as \"store-id\",\n",
    "                        s.\"name\" as \"store-name\"\n",
    "                    from\n",
    "                        \"{read_schema}\".\"patients-metadata-2\" pm\n",
    "                    left join \"{read_schema}\".stores s on\n",
    "                        pm.\"primary-store-id\" = s.id\n",
    "                    where\n",
    "                        DATEDIFF('days', '{period_end_d_plus1}', \"last-bill-date\") between -180 and -1;\n",
    "                    \"\"\"\n",
    "data_store = rs_db.get_df(query=patient_store_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_store['rank'] = data_store.sort_values(['store-bills', 'store-spend'],\n",
    "#                                             ascending=[False, False]\n",
    "#                                             ).groupby(['patient-id']).cumcount() + 1\n",
    "\n",
    "# patient_store = data_store[data_store['rank'] == 1][['patient-id', 'store-id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stores\n",
    "\n",
    "# stores_q = f\"\"\"\n",
    "#     SELECT\n",
    "#         \"id\" AS \"store-id\",\n",
    "#         \"name\" AS \"store-name\"\n",
    "#     FROM \n",
    "#         \"{read_schema}\".\"stores\"\n",
    "#         \"\"\"\n",
    "# stores = rs_db.get_df(query=stores_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient_store = patient_store.merge(stores, how='inner',\n",
    "#                                     on=['store-id', 'store-id'])\n",
    "\n",
    "data = data.merge(data_store, how='left', left_on=['patient-id'],\n",
    "                  right_on=['patient-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfe7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "keep_cols = ['patient-id', 'num-bills-period', 'total-spend-period',\n",
    "             'spend-per-bill', 'units-per-bill',\n",
    "             'generico-age-customer', 'recency-customer', 'quantity-ethical-pc',\n",
    "             'quantity-generic-pc', 'quantity-chronic-pc', 'chronic-yes', 'hd-yes',\n",
    "             'newcomer-flag', 'singletripper-flag', 'behaviour-segment',\n",
    "             'store-id', 'store-name']\n",
    "\n",
    "write_data = data[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round some numbers\n",
    "for i in ['quantity-ethical-pc', 'quantity-generic-pc', 'quantity-chronic-pc']:\n",
    "    write_data[i] = np.round(write_data[i], 2)\n",
    "for i in ['total-spend-period', 'spend-per-bill']:\n",
    "    write_data[i] = np.round(write_data[i], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265de1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = write_data.rename(columns={'units-per-bill': 'quantity-per-bill'})\n",
    "\n",
    "# Make some columns for logging purpose\n",
    "runtime_date = dt.today().strftime('%Y-%m-%d')\n",
    "runtime_month = dt.today().strftime('%Y-%m')\n",
    "\n",
    "write_data['segment-calculation-date'] = period_end_d_plus1\n",
    "write_data['upload-date'] = runtime_date\n",
    "write_data['base-list-identifier'] = runtime_month\n",
    "\n",
    "#data-type correction\n",
    "write_data['generico-age-customer'] = write_data['generico-age-customer'].fillna(0)\n",
    "write_data['store-id'] = write_data['store-id'].fillna(0)\n",
    "write_data['store-id'] = write_data['store-id'].astype(int)\n",
    "logger.info(write_data.info())\n",
    "\n",
    "# etl\n",
    "write_data['created-at'] = dt.now(tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "write_data['created-by'] = 'etl-automation'\n",
    "write_data['updated-at'] = dt.now(tz=gettz('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "write_data['updated-by'] = 'etl-automation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f979f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(table_info, type(None)):\n",
    "    print(f\"table: {table_name} do not exist\")\n",
    "else:\n",
    "    truncate_query = f''' DELETE FROM \"{schema}\".\"{table_name}\" \n",
    "                        WHERE \"segment-calculation-date\" =  '{period_end_d_plus1}' \n",
    "                        '''\n",
    "    logger.info(truncate_query)\n",
    "    rs_db.execute(truncate_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41121e50-95f5-4a7f-93e1-57d7177d51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates subset - patient-id\n",
    "write_data.drop_duplicates(subset=['patient-id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.save_df_to_s3(df=write_data, \n",
    "                 file_name='Behaviour_Segment_Output/behaviour_segment_data_{}.csv'.format(calc_year_month), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Append this updated_churn to Redshift DB\n",
    "###################################################\n",
    "\n",
    "s3.write_df_to_db(df=write_data[table_info['column_name']], table_name=table_name, db=rs_db, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = Email()\n",
    "\n",
    "subject = \"Task Status behaviour segment calculation\"\n",
    "mail_body = \"Behaviour segments upload succeeded\"\n",
    "\n",
    "file_uris= [profile_data_all, profile_data_med_all]\n",
    "    \n",
    "email.send_email_file(subject=subject,\n",
    "                      mail_body=mail_body,\n",
    "                      to_emails=email_to, file_uris=file_uris, file_paths=[])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
