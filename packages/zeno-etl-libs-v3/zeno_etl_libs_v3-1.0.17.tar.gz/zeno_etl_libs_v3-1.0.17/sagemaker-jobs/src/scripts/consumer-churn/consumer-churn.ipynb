{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab122ad-82aa-4941-880d-ef80c1814868",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandasql\n",
    "!pip install zeno_etl_libs_v3==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224545d-756b-4ffb-b014-00aa18f8a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author:shubham.gupta@zeno.health\n",
    "Purpose: Churn prediction\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "from pickle import load, dump\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b17c8-2b09-494d-a5d7-dbb6aa39f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../..')\n",
    "\n",
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.db.db import DB\n",
    "from zeno_etl_libs.helper import helper\n",
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.helper.email.email import Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9615e-425f-4342-a671-ee46eb4a8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76f224-69ef-463a-93be-9a98ebeba65c",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "env = \"dev\"\n",
    "email_to = [\"shubham.gupta@zeno.health\"]\n",
    "re_train = 1\n",
    "features = []\n",
    "schema = \"prod2-generico\"\n",
    "prod_write = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9227b4d-869e-4752-acc3-26e1ccbbe900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params ( retrain or just predict from trained model )\n",
    "if re_train:\n",
    "    end = str(dt.today().date())\n",
    "    start = str(dt.today().date() - relativedelta(months=7))\n",
    "else:\n",
    "    end = str(dt.today().date())\n",
    "    start = str(dt.today().date() - relativedelta(months=6))\n",
    "    features = ['patient-id'] + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38705c68-b3c6-4e52-9497-c322ce637c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['env'] = env\n",
    "logger = get_logger()\n",
    "logger.info(f\"env: {env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef46409-b8f7-4922-9e01-35ae939811cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_name = 'customer-behaviour-segment'\n",
    "\n",
    "rs_db = DB()\n",
    "rs_db.open_connection()\n",
    "\n",
    "table_name = 'consumer-churn'\n",
    "rs_db_write = DB(read_only=prod_write)\n",
    "rs_db_write.open_connection()\n",
    "\n",
    "s3 = S3(bucket_name='datascience-manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cc013-add7-4e05-9a84-75b856595897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seek():\n",
    "    \"\"\" get the data \"\"\"\n",
    "    pass\n",
    "def run_fun(rs_db, s3):\n",
    "    # write logic here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bbd59-bea3-4f04-961e-c95dc79adb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = helper.get_table_info(db=rs_db_write, table_name=table_name, schema=schema)\n",
    "logger.info(table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a4a31-5988-485c-94e5-b8b044367a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_schema = 'prod2-generico'\n",
    "\n",
    "if isinstance(table_info, type(None)):\n",
    "     print(f\"table: {table_name} do not exist\") \n",
    "else:\n",
    "    truncate_query = f\"\"\"                \n",
    "                    DELETE\n",
    "                        FROM\n",
    "                    \"{read_schema}\".\"consumer-churn\"\n",
    "                    WHERE\n",
    "                        DATE(\"created-at\") = '{dt.now().date()}';\"\"\"    \n",
    "    logger.info(truncate_query)\n",
    "    rs_db_write.execute(truncate_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c0b77-9119-4f66-91f1-57719e79707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fetching\n",
    "\n",
    "data_q = f\"\"\"\n",
    "        select\n",
    "            rm.\"patient-id\"  ,\n",
    "            rm.id as \"bill-id\",\n",
    "            rm.\"bill-date\",\n",
    "            rm.\"created-at\" as \"bill-created-at\",\n",
    "            rm.\"total-spend\",\n",
    "            rm.\"spend-generic\", \n",
    "            rm.\"value-segment\", \n",
    "            rm.\"system-age-days\" as \"system-age\"\n",
    "        from\n",
    "            \"{read_schema}\".\"retention-master\" rm \n",
    "        where\n",
    "            rm.\"bill-date\" between '{start}' and '{end}';\n",
    "        \"\"\"\n",
    "\n",
    "data = rs_db.get_df(data_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0ff6b-0948-4cf8-9269-5d72dc690666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_creator(bill_data, re_train, features=[]) :\n",
    "    # Preparing dataset\n",
    "    data['bill-date'] = pd.to_datetime(data['bill-date'])\n",
    "\n",
    "    if re_train:\n",
    "        df_end = str(dt.today().date() + relativedelta(months=-1))\n",
    "    else:\n",
    "        df_end = str(dt.today().date())\n",
    "\n",
    "    df = data[(data['bill-date'] < df_end)]\n",
    "    df = df[['patient-id', 'bill-id', 'bill-date', 'bill-created-at', 'total-spend',\n",
    "             'spend-generic', 'value-segment', 'system-age']]\n",
    "    logger.info(df.info())\n",
    "\n",
    "    # data type correction\n",
    "    df['total-spend'] = df['total-spend'].astype(float)\n",
    "    df['spend-generic'] = df['spend-generic'].astype(float)\n",
    "\n",
    "    # total spend and ABV in 6 months\n",
    "    df2_nob_spend = df.groupby('patient-id', as_index=False).agg({'bill-id': 'nunique',\n",
    "                                                                  'total-spend': ['mean', 'sum'],\n",
    "                                                                  'spend-generic': 'sum'})\n",
    "    df2_nob_spend['generic-pc'] = df2_nob_spend[('spend-generic', 'sum')] / df2_nob_spend[('total-spend', 'sum')]\n",
    "    df2_nob_spend = df2_nob_spend.drop(columns=[('spend-generic', 'sum')])\n",
    "    df2_nob_spend.columns = ['patient-id', 'nob', 'abv', 'total-spend', 'generic-pc']\n",
    "\n",
    "    df3_rec_bill = df.sort_values('bill-created-at', ascending=False)\n",
    "\n",
    "    df3_rec_bill = df3_rec_bill.groupby('patient-id', as_index=False).head(1)\n",
    "    df3_rec_bill['value-segment'] = df3_rec_bill['value-segment'].map({'platinum': 4,\n",
    "                                                                       'gold': 3,\n",
    "                                                                       'silver': 2,\n",
    "                                                                       'others': 1})\n",
    "    df3_rec_bill.loc[:, 'today'] = df_end\n",
    "    df3_rec_bill['recency'] = pd.to_datetime(df3_rec_bill['today']) - df3_rec_bill['bill-date']\n",
    "    df3_rec_bill['recency'] = df3_rec_bill['recency'].dt.days\n",
    "    df3_rec_bill = df3_rec_bill[['patient-id', 'recency', 'system-age', 'value-segment']]\n",
    "\n",
    "    df4_bill_diff = df[['bill-id', 'patient-id', 'bill-date']]\n",
    "    df4_bill_diff = df4_bill_diff.sort_values('bill-date')\n",
    "    df4_bill_diff['shifted-date'] = df4_bill_diff.groupby('patient-id', as_index=False)['bill-date'].shift(1)\n",
    "    df4_bill_diff['bill-diff'] = df4_bill_diff['bill-date'] - df4_bill_diff['shifted-date']\n",
    "    df4_bill_diff['bill-diff'] = df4_bill_diff['bill-diff'].dt.days\n",
    "    df4_bill_diff['bill-diff'] = df4_bill_diff.groupby('patient-id', as_index=False)['bill-diff'].backfill()\n",
    "    df4_bill_diff = df4_bill_diff.groupby('patient-id', as_index=False).agg({'bill-diff': ['mean', 'std']})\n",
    "    df4_bill_diff = df4_bill_diff.fillna(0)\n",
    "    df4_bill_diff.columns = ['patient-id', 'mean-purchase-interval', 'std-purchase-interval']\n",
    "\n",
    "    final_df = pd.merge(df2_nob_spend, df3_rec_bill, on='patient-id', how='left')\n",
    "    final_df = pd.merge(final_df, df4_bill_diff, on='patient-id', how='left')\n",
    "\n",
    "    for i in final_df.columns:\n",
    "        if final_df[i].dtype == 'float64':\n",
    "            final_df[i] = final_df[i].round(4)\n",
    "\n",
    "    if re_train:\n",
    "        train_label = data[(data['bill-date'] >= df_end)]\n",
    "        train_label = train_label[['patient-id']].drop_duplicates()\n",
    "        train_label['churn'] = 0\n",
    "\n",
    "        final_df = pd.merge(final_df, train_label, on='patient-id', how='left')\n",
    "        final_df['churn'] = final_df['churn'].fillna(1)\n",
    "        final_df = final_df.drop_duplicates(subset='patient-id')\n",
    "    else:\n",
    "        final_df = final_df.drop_duplicates(subset='patient-id')\n",
    "        final_df = final_df[features]\n",
    "\n",
    "    final_df = final_df.dropna()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94603166-4601-458c-a97e-19359009ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list type, with optimal cutoff value\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr))\n",
    "    roc = pd.DataFrame(\n",
    "        {'tf': pd.Series(tpr - (1 - fpr), index=i), 'threshold': pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3b2f0-bb11-482c-8410-6aa099a1247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_train == 1 :\n",
    "    final_df = dataframe_creator(data, re_train=1, features=[])\n",
    "else :\n",
    "    final_df = dataframe_creator(data, re_train=0, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6aa0a7-0d61-4a87-af8d-b84981c48ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_train:\n",
    "    y = final_df[['churn']]\n",
    "    X = final_df.drop(columns=['churn', 'patient-id'])\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=0,\n",
    "                                                        stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                      y_train,\n",
    "                                                      test_size=0.20,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify=y_train)\n",
    "\n",
    "    # Baseline DecisionTree Model\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train, y_train)\n",
    "    dtc_report = classification_report(y_val, dtc.predict(X_val))\n",
    "    logger.info('decision_tree baseline model classification report validation data : '\n",
    "                '{}'.format(dtc_report))\n",
    "    # extracting all alphas\n",
    "    alphas = dtc.cost_complexity_pruning_path(X_train, y_train)\n",
    "    alphas = alphas['ccp_alphas']\n",
    "    # finding best alphas\n",
    "    g_search = GridSearchCV(dtc,\n",
    "                            param_grid={'ccp_alpha': list(set(alphas.round(6)))},\n",
    "                            cv=5,\n",
    "                            scoring='roc_auc',\n",
    "                            n_jobs=-1,\n",
    "                            verbose=0)\n",
    "\n",
    "    # fit the grid search to the data\n",
    "    g_search.fit(X_train, y_train)\n",
    "    # putting best params in DT\n",
    "    dtc = DecisionTreeClassifier(**g_search.best_params_)\n",
    "    dtc.fit(X_train, y_train)\n",
    "\n",
    "    # bp = best params\n",
    "    dtc_report_bp_train = classification_report(y_train, dtc.predict(X_train))\n",
    "    dtc_report_bp_val = classification_report(y_val, dtc.predict(X_val))\n",
    "    logger.info('decision_tree tuned model classification report train : '\n",
    "                '{}'.format(dtc_report_bp_train))\n",
    "    logger.info('decision_tree tuned model classification report validation : '\n",
    "                '{}'.format(dtc_report_bp_val))\n",
    "\n",
    "    ft_imp = pd.DataFrame(data=dtc.feature_importances_,\n",
    "                          index=X_train.columns).sort_values(0, ascending=False)\n",
    "    ft_imp[1] = ft_imp[0].cumsum()\n",
    "    \n",
    "    # feature selection\n",
    "    feat_selection = ft_imp[ft_imp[1] < 0.90]\n",
    "\n",
    "    if len(feat_selection) <= 5:\n",
    "        feat = ft_imp.index[:5]\n",
    "    else:\n",
    "        feat = feat_selection.index\n",
    "\n",
    "    X_train = X_train[feat]\n",
    "    X_test = X_test[feat]\n",
    "    X_val = X_val[feat]\n",
    "    X = X[feat]\n",
    "\n",
    "    logger.info('feature selected : {}'.format(feat))\n",
    "\n",
    "    # Taking best params from DT\n",
    "    depth = np.linspace(dtc.get_depth() / 2, dtc.get_depth(), 5).round()\n",
    "    alpha = dtc.ccp_alpha\n",
    "\n",
    "    # Create the parameter grid based on the results of best decision tree\n",
    "    param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': depth,\n",
    "        'max_features': [\"sqrt\", \"log2\"],\n",
    "        'ccp_alpha': [alpha],\n",
    "        'n_estimators': [25, 50, 75, 100, 150, 200, 250]\n",
    "    }\n",
    "    \n",
    "    # Create a based model\n",
    "    rf = RandomForestClassifier()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                               cv=5, n_jobs=-1, verbose=0, scoring='roc_auc')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    rf = RandomForestClassifier(**grid_search.best_params_)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # classification report\n",
    "    rf_report_bp_train = classification_report(y_train, rf.predict(X_train))\n",
    "    rf_report_bp_val = classification_report(y_val, rf.predict(X_val))\n",
    "    rf_report_bp_test = classification_report(y_test, rf.predict(X_test))\n",
    "    logger.info('random_forest tuned model classification report train : '\n",
    "                '{}'.format(rf_report_bp_train))\n",
    "    logger.info('random_forest tuned model classification report validation : '\n",
    "                '{}'.format(rf_report_bp_val))\n",
    "    logger.info('random_forest tuned model classification report test : '\n",
    "                '{}'.format(rf_report_bp_test))\n",
    "\n",
    "\n",
    "    cutoff = find_optimal_cutoff(y_train, rf.predict_proba(X_train)[:, 1])[0]\n",
    "    # Train data\n",
    "    #plot_roc_curve(rf, X_train, y_train)\n",
    "    # plt.savefig(output_dir_path + 'roc_curve_Train.png')\n",
    "    logger.info('optimal cutoff  value : {}'.format(round(cutoff, 3)))\n",
    "\n",
    "    # Validation data\n",
    "    #plot_roc_curve(rf, X_val, y_val)\n",
    "    # plt.savefig(output_dir_path + 'roc_curve_Val.png')\n",
    "\n",
    "    # Test data\n",
    "    #plot_roc_curve(rf, X_test, y_test)\n",
    "    # plt.savefig(output_dir_path + 'roc_curve_Test.png')\n",
    "\n",
    "    # # Saving model\n",
    "    # dump(rf, open(output_dir_path + 'model.pkl', 'wb'))\n",
    "    # script_manager_obj.s3_admin_obj.upload_object(output_dir_path + 'model.pkl',\n",
    "    #                                               f'data/Job-{script_manager_obj.job_id}/input/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d8ae4-1b99-42ad-9ea0-66f3f71386b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_train:\n",
    "    final_df = dataframe_creator(data, re_train=0, features=feat)\n",
    "    final_df['churn-prob'] = rf.predict_proba(final_df)[:, 1]\n",
    "    final_df['churn-prediction'] = np.where(final_df['churn-prob'] >= cutoff, 1, 0)\n",
    "    final_df['created-at'] = dt.now().date()\n",
    "    final_df['re-trained'] = 1\n",
    "else:\n",
    "    # script_manager_obj.s3_admin_obj.get_object(f'data/Job-{script_manager_obj.job_id}/input/model.pkl',\n",
    "    #                                            input_dir_path)\n",
    "    # rf = load(open(input_dir_path + 'model.pkl', 'rb'))\n",
    "    pred = final_df.drop(columns=['patient-id'])\n",
    "    final_df['churn-prob'] = rf.predict_proba(pred)[:, 1]\n",
    "    final_df['churn-prediction'] = np.where(final_df['churn-prob'] >= job_data_params['cutoff'], 1, 0)\n",
    "    final_df['created-at'] = dt.now().date()\n",
    "    final_df['re-trained'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a4bae-f86f-42e3-bba6-7ee33e464da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "s3.save_df_to_s3(df=final_df, \n",
    "                 file_name='consumer_churn_prediction_{}.csv'.format(dt.today()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c20971-330a-4549-9707-e27e778a2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type correction\n",
    "final_df['churn'] = final_df['churn'].astype(int)\n",
    "final_df['value-segment'] = final_df['value-segment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ca905-f7ae-4daf-a8f6-5e60949a0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to db\n",
    "s3.write_df_to_db(df=final_df[table_info['column_name']], \n",
    "                  table_name=table_name, db=rs_db_write, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b53e03-2dc5-4596-a340-c60592fec8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = Email()\n",
    "\n",
    "subject = \"Task status churn calcualtion\"\n",
    "mail_body = \"Churn data upload succeeded\"\n",
    "\n",
    "file_uris= []\n",
    "    \n",
    "email.send_email_file(subject=subject,\n",
    "                      mail_body=mail_body,\n",
    "                      to_emails=email_to, file_uris=file_uris, file_paths=[])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee6656-bb03-4241-8adc-48f4b08c3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for action_dict in actions_list:\n",
    "#     if action_dict['category'] == 'EML':\n",
    "#         to_emails = action_dict['email_to']\n",
    "#         subject = 'churn prediction algo status : {}'.format(status)\n",
    "#         mail_body = 'Table fetch from  {} to {} '.format(start, end)\n",
    "#         if job_data_params['re_train']:\n",
    "#             file_paths = [output_dir_path + 'debug_{}.txt'.format(script_manager_obj.job_id),\n",
    "#                           output_dir_path + 'roc_curve_Train.png',\n",
    "#                           output_dir_path + 'roc_curve_Val.png',\n",
    "#                           output_dir_path + 'roc_curve_Test.png']\n",
    "#         else:\n",
    "#             file_paths = [output_dir_path + 'debug_{}.txt'.format(script_manager_obj.job_id)]\n",
    "#         send_email_file(subject, mail_body, to_emails, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acb19c-257a-4142-b235-83ef3db8b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
