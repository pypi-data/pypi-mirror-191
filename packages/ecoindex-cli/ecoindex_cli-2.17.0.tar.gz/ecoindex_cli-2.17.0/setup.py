# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['ecoindex_cli', 'ecoindex_cli.cli', 'ecoindex_cli.report']

package_data = \
{'': ['*'], 'ecoindex_cli.report': ['translations/*']}

install_requires = \
['Jinja2>=3.0.1,<4.0.0',
 'PyYAML>=6.0,<7.0',
 'Scrapy>=2.5.0,<3.0.0',
 'click-spinner>=0.1.10,<0.2.0',
 'ecoindex-scraper>=2.15.0,<3.0.0',
 'matplotlib>=3.4.3,<4.0.0',
 'pandas>=1.3.3,<2.0.0',
 'pydantic>=1.10.2,<2.0.0',
 'typer>=0.3.2,<0.8.0']

entry_points = \
{'console_scripts': ['ecoindex-cli = ecoindex_cli.cli.app:app']}

setup_kwargs = {
    'name': 'ecoindex-cli',
    'version': '2.17.0',
    'description': '`ecoindex-cli` is a CLI tool that let you make ecoindex tests on given pages',
    'long_description': '# Ecoindex-Cli\n\n[![Quality check](https://github.com/cnumr/ecoindex_cli/workflows/Quality%20checks/badge.svg)](https://github.com/cnumr/ecoindex_cli/actions/workflows/quality.yml)\n[![PyPI version](https://badge.fury.io/py/ecoindex-cli.svg)](https://badge.fury.io/py/ecoindex-cli)\n\nThis tool provides an easy way to analyze websites with [Ecoindex](https://www.ecoindex.fr) from your local computer using multi-threading. You have the ability to:\n\n- Make the analysis on multiple pages\n- Define multiple screen resolution\n- Make a recursive analysis from a given website\n\nThis CLI is built on top of [ecoindex-python](https://pypi.org/project/ecoindex/) with [Typer](https://typer.tiangolo.com/)\n\nThe output is always a CSV file with the results of the analysis.\n\n## Requirements\n\n- Python ^3.10\n- [pip](https://pip.pypa.io/en/stable/)\n\n## Setup\n\n```bash\npip install --user -U ecoindex-cli\n```\n\n## Use case\n\nThe cli gets 2 commands: `analyze` and `report` which can be used separately:\n\n```bash\necoindex-cli --help                                \n```\n\n```bash\nUsage: ecoindex-cli [OPTIONS] COMMAND [ARGS]...\n\n  Ecoindex cli to make analysis of webpages\n\nOptions:\n  --install-completion [bash|zsh|fish|powershell|pwsh]\n                                  Install completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\n                                  Show completion for the specified shell, to\n                                  copy it or customize the installation.\n\n  --help                          Show this message and exit.\n\nCommands:\n  analyze  Make an ecoindex analysis of given webpages or website.\n  report   If you already performed an ecoindex analysis and have your...\n```\n\n### Make a simple analysis\n\nYou give just one web url\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr\n```\n\n<details><summary>Result</summary>\n\n```bash\nThere are 1 url(s), do you want to process? [Y/n]:\n1 urls for 1 window size\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-20_164433/results.csv written !\n```\n\n</details>\n\n> This makes an analysis with a screen resolution of 1920x1080px by default and with the last known version of chromedriver. You can set those settings with options: `--window-size` and `--chrome-version`\n\n### Set the output file\n\nYou can define the csv output file\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --output-file ~/ecoindex-results/ecoindex.csv\n```\n\n<details><summary>Result</summary>\n\n```bash\nüìÅÔ∏è Urls recorded in file `input/www.ecoindex.fr.csv`\nThere are 1 url(s), do you want to process? [Y/n]:\n1 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /home/vvatelot/ecoindex-results/ecoindex.csv written !\n```\n\n</details>\n\n### Export to JSON file\n\nBy default, the results are exported to a CSV file. But, you can specify to export the results to a JSON file.\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --export-format json\n```\n\n<details><summary>Result</summary>\n\n```bash\nüìÅÔ∏è Urls recorded in file `input/www.ecoindex.fr.csv`\nThere are 1 url(s), do you want to process? [Y/n]:\n1 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2022-03-05_215320/results.json written !\n```\n\n</details>\n\n### Multiple url analysis\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --url https://www.greenit.fr/\n```\n\n<details><summary>Result</summary>\n\n```bash\nThere are 2 url(s), do you want to process? [Y/n]:\n2 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-20_164524/results.csv written !\n```\n\n</details>\n\n### Provide urls from a file\n\nYou can use a file with given urls that you want to analyze: One url per line. This is helpful if you want to play the same scenario recurrently.\n\n```bash\necoindex-cli analyze --urls-file input/ecoindex.csv\n```\n\n<details><summary>Result</summary>\n\n```bash\nThere are 2 url(s), do you want to process? [Y/n]:\n2 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-20_164524/results.csv written !\n```\n\n</details>\n\n### Make a recursive analysis\n\nYou can make a recursive analysis of a given webiste. This means that the app will try to find out all the pages into your website and launch an analysis on all those web pages. ‚ö†Ô∏è This can process for a very long time! **Use it at your own risks!**\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --recursive\n```\n\n<details><summary>Result</summary>\n\n```bash\n‚è≤Ô∏è Crawling root url https://www.ecoindex.fr -> Wait a minute !\nüìÅÔ∏è Urls recorded in file `/tmp/ecoindex-cli/input/www.ecoindex.fr.csv`\nThere are 3 url(s), do you want to process? [Y/n]:\n3 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-20_164729/results.csv written !\n```\n\n</details>\n\n### Using a specific Chrome version\n\nYou can use a specific Chrome version to make the analysis. This is useful if you use an old chrome version. You just have to provide the main Chrome version number.\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --chrome-version 107\n```\n\nOr if you do not know the Chrome version number, you can use the one line command\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --chrome-version (google-chrome --version  | grep --only -P \'(?<=\\\\s)\\\\d{3}\')\n```\n\n### Using multi-threadging\n\nYou can use multi-threading to speed up the analysis when you have a lot of websites to analyze. In this case, you can define the maximum number of workers to use:\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --url https://www.greenit.fr/ --max-workers 10\n```\n\n<details><summary>Result</summary>\n\n```bash\nThere are 2 url(s), do you want to process? [Y/n]:\n2 urls for 1 window size with 10 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-20_164524/results.csv written !\n```\n\n> By default, the number of maximum workers is set to CPU count.\n\n</details>\n\n### Disable console interaction\n\nYou can disable confirmations, and force the app to answer yes to all of them. It can be useful if you need to start the app from another script, or if you have no time to wait it to finish.\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --recursive --no-interaction\n```\n\n<details><summary>Result</summary>\n\n```bash\n‚è≤Ô∏è Crawling root url https://www.ecoindex.fr -> Wait a minute !\nüìÅÔ∏è Urls recorded in file `/tmp/ecoindex-cli/input/www.ecoindex.fr.csv`\n3 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-11-04_081913/results.csv written !\n```\n\n</details>\n\n### Set other screen resolutions\n\nYou can provide other screen resolutions. By default, the screen resolution is `1920x1080px` but you can provide other resolution for example if you want to test ecoindex for mobile.\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --window-size 1920,1080 --window-size 386,540\n```\n\n<details><summary>Result</summary>\n\n```bash\nThere are 1 url(s), do you want to process? [Y/n]:\n1 urls for 2 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-21_212244/results.csv written !\n```\n\n</details>\n\n### Generate a html report\n\nYou can generate a html report easily at the end of the analysis. You just have to add the option `--html-report`.\n\n```bash\necoindex-cli analyze --url https://www.ecoindex.fr --recursive --html-report\n```\n\n<details><summary>Result</summary>\n\n```bash\n‚è≤Ô∏è Crawling root url https://www.ecoindex.fr -> Wait a minute !\nüìÅÔ∏è Urls recorded in file `input/www.ecoindex.fr.csv`\nThere are 3 url(s), do you want to process? [Y/n]:\n3 urls for 1 window size with 2 maximum workers\nProcessing  [####################################]  100%\nüôåÔ∏è File output/www.ecoindex.fr/2021-04-21_212127/results.csv written !\nü¶ÑÔ∏è Amazing! A report has been generated to /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-04-21_212127/index.html\n```\n\n> When generating a html report, the results are written in a CSV file and you can not specify the result file location. So options `--export-format` and `--output-file` are ignored.\n\n</details>\n\nHere is a sample result:\n![Sample report](doc/report.png)\n\n### Only generate a report from existing result file\n\nIf you already performed an anlayzis and (for example), forgot to generate the html report, you do not need to re-run a full analyzis, you can simply request a report from your result file :\n\n```bash\necoindex-cli report "/tmp/ecoindex-cli/output/www.ecoindex.fr/2021-05-06_191355/results.csv" "www.synchrone.fr"\n```\n\n<details><summary>Result</summary>\n\n```bash\nü¶ÑÔ∏è Amazing! A report has been generated to /tmp/ecoindex-cli/output/www.ecoindex.fr/2021-05-06_191355/index.html\n```\n\n</details>\n\n## Results example\n\nThe result of the analysis is a CSV or JSON file which can be easily used for further analysis:\n\n### CSV example\n\n```csv\nwidth,height,url,size,nodes,requests,grade,score,ges,water,date,page_type\n1920,1080,https://www.ecoindex.fr,521.54,45,68,B,75.0,1.5,2.25,2022-05-03 22:28:49.280479,\n1920,1080,https://www.greenit.fr,1374.641,666,167,E,32.0,2.36,3.54,2022-05-03 22:28:51.176216,website\n```\n\n### JSON example\n\n```json\n[\n    {\n        "width": 1920,\n        "height": 1080,\n        "url": "https://www.ecoindex.fr",\n        "size": 521.54,\n        "nodes": 45,\n        "requests": 68,\n        "grade": "B",\n        "score": 75.0,\n        "ges": 1.5,\n        "water": 2.25,\n        "date": "2022-05-03 22:25:01.016749",\n        "page_type": null\n    },\n    {\n        "width": 1920,\n        "height": 1080,\n        "url": "https://www.greenit.fr",\n        "size": 1163.386,\n        "nodes": 666,\n        "requests": 148,\n        "grade": "E",\n        "score": 34.0,\n        "ges": 2.32,\n        "water": 3.48,\n        "date": "2022-05-03 22:25:04.516676",\n        "page_type": "website"\n    }\n]\n```\n\n## Docker\n\nYou can use this application in a docker container. You can build the image with the following command:\n\n```bash\ndocker build -t ecoindex-cli .\n```\n\n> You can set a sepcific chrome version using `--build-arg CHROME_VERSION=107.0.5304.121-1` (default is `107.0.5304.121-1`)\n\nAnd then you can run the container with the following command:\n\n```bash\ndocker run -it --rm -v $(pwd)/output:/tmp ecoindex-cli:latest ecoindex-cli analyze --url https://www.ecoindex.fr --recursive --chrome-version 107\n```\n\n> You have to set the `--chrome-version` option to the same main version as the one used to build the image.\n\n### Fields description\n\n- `width` is the screen width used for the page analysis (in pixels)\n- `height` is the screen height used for the page analysis (in pixels)\n- `url` is the analysed page url\n- `size` is the size of the page and of the downloaded elements of the page in KB\n- `nodes` is the number of the DOM elements in the page\n- `requests` is the number of external requests made by the page\n- `grade` is the corresponding ecoindex grade of the page (from A to G)\n- `score`\xa0is the corresponding ecoindex score of the page (0 to 100)\n- `ges` is the equivalent of greenhouse gases emission (in `gCO2e`) of the page\n- `water`is the equivalent water consumption (in `cl`) of the page\n- `date` is the datetime of the page analysis\n- `page_type` is the type of the page, based ton the [opengraph type tag](https://ogp.me/#types)\n\n## Testing\n\nIn order to develop or test, you have to use [Poetry](https://python-poetry.org/), install the dependencies and execute a poetry shell:\n\n```bash\npoetry install && \\\npoetry shell\n```\n\nWe use Pytest to run unit tests for this project. The test suite are in the `tests` folder. Just execute :\n\n```bash\npytest --cov-report term-missing:skip-covered --cov=. --cov-config=.coveragerc tests\n```\n\n> This runs pytest and also generate a [coverage report](https://pytest-cov.readthedocs.io/en/latest/) (terminal and html)\n\n## Disclaimer\n\nThe LCA values used by [ecoindex_cli](https://github.com/cnumr/ecoindex_cli) to evaluate environmental impacts are not under free license - ¬©Fr√©d√©ric Bordage\nPlease also refer to the mentions provided in the code files for specifics on the IP regime.\n\n## [License](LICENSE)\n\n## [Contributing](CONTRIBUTING.md)\n\n## [Code of conduct](CODE_OF_CONDUCT.md)\n',
    'author': 'Vincent Vatelot',
    'author_email': 'vincent.vatelot@ik.me',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://www.ecoindex.fr',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.10,<4.0',
}


setup(**setup_kwargs)
